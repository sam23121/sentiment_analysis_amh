{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py:104: UserWarning: \n",
      "NVIDIA GeForce RTX 3050 Ti Laptop GPU with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA GeForce RTX 3050 Ti Laptop GPU GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3050 Ti Laptop GPU'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/amh_datasetall .txt\")\n",
    "df.head()\n",
    "df2 = pd.read_csv(\"../data/Amharic_dataset.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38424"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"texts\", \"labels\"]\n",
    "df2.columns = [\"texts\", \"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.concat([df2, df], ignore_index=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_new[df_new[\"texts\"] == \"ፈጣሪ ይባርካቹ\"])\n",
    "df_new.drop_duplicates(inplace=True)\n",
    "len(df_new[df_new[\"texts\"] == \"ፈጣሪ ይባርካቹ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ፈጣሪ ይባርካቹ</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       texts    labels\n",
       "0  ፈጣሪ ይባርካቹ  positive"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[df_new[\"texts\"] == \"ፈጣሪ ይባርካቹ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28682"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/amahric_testdata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50021</th>\n",
       "      <td>መልካም ዉይይት</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50022</th>\n",
       "      <td>ዝናሽን ልገምግማት</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50023</th>\n",
       "      <td>ሞቶ ስዳርስ ነው ንሳ ማግባታ አብይ</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50024</th>\n",
       "      <td>አብይ ሰለ ጉራጌ ተንፍስ   አብይ በጉራጌ ዞን ሚደረገዉ እነደ አልሰማ ዝ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50025</th>\n",
       "      <td>በጉራጌ ዞን ብርሀኑ ነጋ የመረጠዉ የለም  ለምን ጠቅላይ ሚንስተር አብይ ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   texts   labels\n",
       "50021                                          መልካም ዉይይት  neutral\n",
       "50022                                        ዝናሽን ልገምግማት  neutral\n",
       "50023                             ሞቶ ስዳርስ ነው ንሳ ማግባታ አብይ  neutral\n",
       "50024  አብይ ሰለ ጉራጌ ተንፍስ   አብይ በጉራጌ ዞን ሚደረገዉ እነደ አልሰማ ዝ...  neutral\n",
       "50025  በጉራጌ ዞን ብርሀኑ ነጋ የመረጠዉ የለም  ለምን ጠቅላይ ሚንስተር አብይ ...  neutral"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/new_data.csv\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"labels\"] = df[\"labels\"].str.strip()\n",
    "df[\"labels\"] = df[\"labels\"].str.replace(\"neutrall\", \"neutral\", regex=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    21914\n",
       "positive    16063\n",
       "neutral     12043\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    21914\n",
       "positive    16063\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df[df.labels != \"neutral\"]\n",
    "df_new.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    16063\n",
       "positive    16063\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_neg = df_new[df_new.labels == \"negative\"][:16063]\n",
    "df_new_pos = df_new[df_new.labels != \"negative\"]\n",
    "df_redu = pd.concat([df_new_neg, df_new_pos])\n",
    "df_redu.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>የአማራ ፅንፈኛ ሀይሎች እንኳን አብይ አህመድን እርስ በራሳቸው እንኳ ቢሮ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ስለ ሰዉ ማንነት ብቻ እዉቀት ያለው ከሚያውቀው ውጪ ማሠብም ማውራትም አይ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ኣንድ ክልል በዉጫው ሐይል   ህዝብ ያስደበደበስ  የህዝቡንብረት ያስጨረሰ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>አዎ አብረን ዝም እንበል ዘመን ተሻጋሪ ግጥም</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>በጣም  ይገርማል  ያሁሉ ሲሞት  የት  ነበርክ  ኧረ  ሞት  ይሻላል</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts    labels\n",
       "0  የአማራ ፅንፈኛ ሀይሎች እንኳን አብይ አህመድን እርስ በራሳቸው እንኳ ቢሮ...  positive\n",
       "1  ስለ ሰዉ ማንነት ብቻ እዉቀት ያለው ከሚያውቀው ውጪ ማሠብም ማውራትም አይ...  negative\n",
       "2  ኣንድ ክልል በዉጫው ሐይል   ህዝብ ያስደበደበስ  የህዝቡንብረት ያስጨረሰ...  positive\n",
       "3                       አዎ አብረን ዝም እንበል ዘመን ተሻጋሪ ግጥም  positive\n",
       "4        በጣም  ይገርማል  ያሁሉ ሲሞት  የት  ነበርክ  ኧረ  ሞት  ይሻላል  negative"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_redu = df_redu.sample(frac=1).reset_index(drop=True)\n",
    "df_redu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32132"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_redu[\"texts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'positive', 'negative', '\\tnegative', '\\tpositive',\n",
       "       'neutra', nan], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"labels\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "texts     ከቆለጥ ማንጠልጠል የተረፍንበት ሰባተኛዉ ዓመት እያከበርን ባለንበት ጊዜ ...\n",
       "labels                                             positive\n",
       "Name: 2693, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[df[\"labels\"] == \"neutrall\"]\n",
    "df_redu.loc[2693]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative     21914\n",
       "positive     16064\n",
       "positivel    12042\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32132"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df_redu[\"labels\"].to_list()\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32132"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = df_redu[\"texts\"].to_list()\n",
    "len(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = set(\n",
    "    \"\"\"\n",
    "ግን አንቺ አንተ እናንተ ያንተ ያንቺ የናንተ ራስህን ራስሽን ራሳችሁን\n",
    "ሁሉ ኋላ በሰሞኑ አሉ በኋላ ሁኔታ በኩል አስታውቀዋል ሆነ በውስጥ\n",
    "አስታውሰዋል ሆኑ ባጣም እስካሁን ሆኖም በተለይ አሳሰበ ሁል በተመለከተ\n",
    "አሳስበዋል ላይ በተመሳሳይ አስፈላጊ ሌላ የተለያየ አስገነዘቡ ሌሎች የተለያዩ\n",
    "አስገንዝበዋል ልዩ ተባለ አብራርተዋል መሆኑ ተገለጸ አስረድተዋል  ተገልጿል\n",
    "ማለቱ ተጨማሪ እባክህ የሚገኝ ተከናወነ እባክሽ ማድረግ ችግር አንጻር ማን\n",
    "ትናንት እስኪደርስ ነበረች እንኳ ሰሞኑን ነበሩ እንኳን ሲሆን ነበር እዚሁ ሲል\n",
    "ነው እንደገለጹት አለ ና እንደተናገሩት ቢሆን ነገር እንዳስረዱት ብለዋል ነገሮች\n",
    "እንደገና ብዙ ናት ወቅት ቦታ ናቸው እንዲሁም በርካታ አሁን እንጂ እስከ\n",
    "ማለት የሚሆኑት ስለማናቸውም ውስጥ ይሆናሉ ሲባል ከሆነው ስለዚሁ ከአንድ\n",
    "ያልሆነ ሳለ የነበረውን ከአንዳንድ በማናቸውም በሙሉ የሆነው ያሉ በእነዚሁ\n",
    "ወር መሆናቸው ከሌሎች በዋና አንዲት ወይም\n",
    "በላይ እንደ በማቀድ ለሌሎች በሆኑ ቢሆንም ጊዜና  ይሆኑበታል በሆነ አንዱ\n",
    "ለዚህ ለሆነው ለነዚህ ከዚህ የሌላውን ሶስተኛ አንዳንድ ለማንኛውም የሆነ ከሁለት\n",
    "የነገሩ ሰኣት አንደኛ እንዲሆን እንደነዚህ ማንኛውም ካልሆነ የሆኑት  ጋር ቢያንስ\n",
    "ይህንንም እነደሆነ እነዚህን ይኸው  የማናቸውም\n",
    "በሙሉም ይህችው በተለይም አንዱን የሚችለውን በነዚህ ከእነዚህ በሌላ\n",
    "የዚሁ ከእነዚሁ ለዚሁ በሚገባ ለእያንዳንዱ የአንቀጹ ወደ ይህም ስለሆነ ወይ\n",
    "ማናቸውንም ተብሎ እነዚህ መሆናቸውን የሆነችን ከአስር ሳይሆን ከዚያ የለውም\n",
    "የማይበልጥ እንደሆነና እንዲሆኑ  በሚችሉ ብቻ ብሎ ከሌላ የሌላቸውን\n",
    "ለሆነ በሌሎች ሁለቱንም በቀር ይህ በታች አንደሆነ በነሱ\n",
    "ይህን የሌላ እንዲህ ከሆነ ያላቸው በነዚሁ በሚል የዚህ ይህንኑ\n",
    "በእንደዚህ ቁጥር ማናቸውም ሆነው ባሉ በዚህ በስተቀር ሲሆንና\n",
    "በዚህም መሆን ምንጊዜም እነዚህም በዚህና ያለ ስም\n",
    "ሲኖር ከዚህም መሆኑን በሁኔታው የማያንስ እነዚህኑ ማንም ከነዚሁ\n",
    "ያላቸውን እጅግ ሲሆኑ ለሆኑ ሊሆን  ለማናቸውም\n",
    "\"\"\".split()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stop_words(ls):\n",
    "    new_ls_stop = []\n",
    "    for input in ls:\n",
    "        cleaned = [w for w in input.split(\" \") if not w in STOP_WORDS]\n",
    "        new_ls_stop.append(\" \".join(cleaned).strip())\n",
    "\n",
    "    return new_ls_stop\n",
    "    \n",
    "def remove_emojis(ls):\n",
    "    new_ls = []\n",
    "    for input in ls:\n",
    "        new_ls.append(emoji.replace_emoji(input)\n",
    ")\n",
    "    return new_ls\n",
    "    \n",
    "def remove_punc_and_special_chars(ls): \n",
    "    new_ls = []\n",
    "    for text in ls:\n",
    "        text = str(text)\n",
    "        normalized_text = re.sub('[\\!\\@\\#\\$\\%\\^\\«\\»\\&\\*\\(\\)\\…\\[\\]\\{\\}\\;\\“\\”\\›\\’\\‘\\\"\\'\\:\\,\\.\\‹\\/\\<\\>\\?\\\\\\\\|\\`\\´\\~\\-\\=\\+\\፡\\።\\፤\\;\\፦\\፥\\፧\\፨\\፠\\፣]', '',text)\n",
    "        new_ls.append(normalized_text)\n",
    "    return new_ls\n",
    "\n",
    "def remove_ascii_and_numbers(ls):\n",
    "    new_ls = []\n",
    "    for text_input in ls:\n",
    "        text_input = str(text_input)\n",
    "        rm_num_and_ascii=re.sub('[A-Za-z0-9]','',text_input)\n",
    "        text = re.sub('[\\'\\u1369-\\u137C\\']+','',rm_num_and_ascii)\n",
    "        new_ls.append(text)\n",
    "    return new_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32132"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ls = remove_punc_and_special_chars(ls)\n",
    "new_ls = remove_ascii_and_numbers(new_ls)\n",
    "new_ls = remove_emojis(new_ls)\n",
    "new_ls = filter_stop_words(new_ls)\n",
    "len(new_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_char_level_missmatch(ls):\n",
    "        new_ls = []\n",
    "        for input_token in ls:\n",
    "                input_token = str(input_token)\n",
    "                rep1=re.sub('[ሃኅኃሐሓኻ]','ሀ',input_token)\n",
    "                rep2=re.sub('[ሑኁዅ]','ሁ',rep1)\n",
    "                rep3=re.sub('[ኂሒኺ]','ሂ',rep2)\n",
    "                rep4=re.sub('[ኌሔዄ]','ሄ',rep3)\n",
    "                rep5=re.sub('[ሕኅ]','ህ',rep4)\n",
    "                rep6=re.sub('[ኆሖኾ]','ሆ',rep5)\n",
    "                rep7=re.sub('[ሠ]','ሰ',rep6)\n",
    "                rep8=re.sub('[ሡ]','ሱ',rep7)\n",
    "                rep9=re.sub('[ሢ]','ሲ',rep8)\n",
    "                rep10=re.sub('[ሣ]','ሳ',rep9)\n",
    "                rep11=re.sub('[ሤ]','ሴ',rep10)\n",
    "                rep12=re.sub('[ሥ]','ስ',rep11)\n",
    "                rep13=re.sub('[ሦ]','ሶ',rep12)\n",
    "                rep14=re.sub('[ዓኣዐ]','አ',rep13)\n",
    "                rep15=re.sub('[ዑ]','ኡ',rep14)\n",
    "                rep16=re.sub('[ዒ]','ኢ',rep15)\n",
    "                rep17=re.sub('[ዔ]','ኤ',rep16)\n",
    "                rep18=re.sub('[ዕ]','እ',rep17)\n",
    "                rep19=re.sub('[ዖ]','ኦ',rep18)\n",
    "                rep20=re.sub('[ጸ]','ፀ',rep19)\n",
    "                rep21=re.sub('[ጹ]','ፁ',rep20)\n",
    "                rep22=re.sub('[ጺ]','ፂ',rep21)\n",
    "                rep23=re.sub('[ጻ]','ፃ',rep22)\n",
    "                rep24=re.sub('[ጼ]','ፄ',rep23)\n",
    "                rep25=re.sub('[ጽ]','ፅ',rep24)\n",
    "                rep26=re.sub('[ጾ]','ፆ',rep25)\n",
    "                #Normalizing words with Labialized Amharic characters such as በልቱዋል or  በልቱአል to  በልቷል  \n",
    "                rep27=re.sub('(ሉ[ዋአ])','ሏ',rep26)\n",
    "                rep28=re.sub('(ሙ[ዋአ])','ሟ',rep27)\n",
    "                rep29=re.sub('(ቱ[ዋአ])','ቷ',rep28)\n",
    "                rep30=re.sub('(ሩ[ዋአ])','ሯ',rep29)\n",
    "                rep31=re.sub('(ሱ[ዋአ])','ሷ',rep30)\n",
    "                rep32=re.sub('(ሹ[ዋአ])','ሿ',rep31)\n",
    "                rep33=re.sub('(ቁ[ዋአ])','ቋ',rep32)\n",
    "                rep34=re.sub('(ቡ[ዋአ])','ቧ',rep33)\n",
    "                rep35=re.sub('(ቹ[ዋአ])','ቿ',rep34)\n",
    "                rep36=re.sub('(ሁ[ዋአ])','ኋ',rep35)\n",
    "                rep37=re.sub('(ኑ[ዋአ])','ኗ',rep36)\n",
    "                rep38=re.sub('(ኙ[ዋአ])','ኟ',rep37)\n",
    "                rep39=re.sub('(ኩ[ዋአ])','ኳ',rep38)\n",
    "                rep40=re.sub('(ዙ[ዋአ])','ዟ',rep39)\n",
    "                rep41=re.sub('(ጉ[ዋአ])','ጓ',rep40)\n",
    "                rep42=re.sub('(ደ[ዋአ])','ዷ',rep41)\n",
    "                rep43=re.sub('(ጡ[ዋአ])','ጧ',rep42)\n",
    "                rep44=re.sub('(ጩ[ዋአ])','ጯ',rep43)\n",
    "                rep45=re.sub('(ጹ[ዋአ])','ጿ',rep44)\n",
    "                rep46=re.sub('(ፉ[ዋአ])','ፏ',rep45)\n",
    "                rep47=re.sub('[ቊ]','ቁ',rep46) #ቁ can be written as ቊ\n",
    "                rep48=re.sub('[ኵ]','ኩ',rep47) #ኩ can be also written as ኵ  \n",
    "                new_ls.append(rep48)\n",
    "        return new_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32132"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ls = normalize_char_level_missmatch(new_ls)\n",
    "len(new_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32132"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ls2 = []\n",
    "for text in new_ls:\n",
    "    text = re.sub(\"[\\ufeff]\",'',text)\n",
    "    new_ls2.append(text)\n",
    "len(new_ls2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15099/3941556320.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_text2 = ' '.join(new_ls2)\n",
    "# create a list of words\n",
    "words = all_text2.split()\n",
    "# Count all the words using Counter Method\n",
    "count_words = Counter(words)\n",
    "\n",
    "total_words = len(words)\n",
    "sorted_words = count_words.most_common(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348258"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32132\n"
     ]
    }
   ],
   "source": [
    "reviews_int = []\n",
    "for review in new_ls2:\n",
    "    r = [vocab_to_int[w] for w in review.split()]\n",
    "    reviews_int.append(r)\n",
    "# print (reviews_int[0:3])\n",
    "print(len(reviews_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_labels = [1 if label =='positive' elif label == \"\" 0 for label in labels_split]\n",
    "import numpy as np\n",
    "encoded_labels = []\n",
    "for label in labels:\n",
    "    # if label == \"strongNegative\":\n",
    "    #     encoded_labels.append(0)\n",
    "    if label == \"negative\":\n",
    "        encoded_labels.append(0)\n",
    "    # elif label == \"neutral\":\n",
    "    #     encoded_labels.append(1)\n",
    "    else:\n",
    "        encoded_labels.append(1)\n",
    "    # else:\n",
    "    #     encoded_labels.append(4)\n",
    "encoded_labels = np.array(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32132"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    32132.000000\n",
       "mean        10.838354\n",
       "std         14.610802\n",
       "min          0.000000\n",
       "25%          4.000000\n",
       "50%          7.000000\n",
       "75%         13.000000\n",
       "max        703.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "reviews_len = [len(x) for x in reviews_int]\n",
    "pd.Series(reviews_len).hist()\n",
    "plt.show()\n",
    "pd.Series(reviews_len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32132"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_int = [ reviews_int[i] for i, l in enumerate(reviews_len) if l>0 ]\n",
    "encoded_labels = [ encoded_labels[i] for i, l in enumerate(reviews_len) if l> 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_features(reviews_int, seq_length):\n",
    "    ''' Return features of review_ints, where each review is padded with 0's or truncated to the input seq_length.\n",
    "    '''\n",
    "    features = np.zeros((len(reviews_int), seq_length), dtype = int)\n",
    "    \n",
    "    for i, review in enumerate(reviews_int):\n",
    "        review_len = len(review)\n",
    "        \n",
    "        if review_len <= seq_length:\n",
    "            zeroes = list(np.zeros(seq_length-review_len))\n",
    "            new = zeroes+review\n",
    "        elif review_len > seq_length:\n",
    "            new = review[0:seq_length]\n",
    "        \n",
    "        features[i,:] = np.array(new)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0     0     0     0     0     0    67  1570   497    12\n",
      "   6003   862  2513   632  4716 12691  8189 17905]\n",
      " [    0    56   179   931  5287    32 17906   449 17907 31059   251    56\n",
      "    218  4717    56   218    88  2514    13  3346]\n",
      " [   11    26 31060   127     3 31061 31062 31063    53   252  2111   704\n",
      "    146  9854   820   471 31064     2 31065 31066]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0   549   932    61  2003    71  9855  2856]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     8\n",
      "    257  3347  2004    79  2686   112   170   199]\n",
      " [    0     0     0     0     0     0     0     0   933   103  1133 31068\n",
      "  17908 31069   297 31070 17909    10 31071     5]\n",
      " [    0     0     0     0     0     0     0     0     0 31072 31073 31074\n",
      "    836   450   486 31075  9856  1249    45  6004]\n",
      " [    0     0     0   216     1   168 17910   298     6     1    26   475\n",
      "    322 17911   723  8190     7  6959 12692    38]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     7  1050  1050  6960  1906  9857]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0 31076    21  2365 31077]]\n"
     ]
    }
   ],
   "source": [
    "features = pad_features(reviews_int, 20)\n",
    "print (features[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_frac = 0.8\n",
    "train_x = features[0:int(split_frac*len(features))]\n",
    "train_y = encoded_labels[0:int(split_frac*len(features))]\n",
    "remaining_x = features[int(split_frac*len(features)):]\n",
    "remaining_y = encoded_labels[int(split_frac*len(features)):]\n",
    "valid_x = remaining_x[0:int(len(remaining_x)*0.5)]\n",
    "valid_y = remaining_y[0:int(len(remaining_y)*0.5)]\n",
    "test_x = remaining_x[int(len(remaining_x)*0.5):]\n",
    "test_y = remaining_y[int(len(remaining_y)*0.5):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ..., 12691,  8189, 17905],\n",
       "       [    0,    56,   179, ...,  2514,    13,  3346],\n",
       "       [   11,    26, 31060, ...,     2, 31065, 31066],\n",
       "       ...,\n",
       "       [   47, 84536, 84537, ..., 84541,  1073,   870],\n",
       "       [    0,     0,     0, ..., 84552,   268,   192],\n",
       "       [    0,     0,     0, ...,   222,  1785,  2316]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(np.array(train_x)), torch.from_numpy(np.array(train_y)))\n",
    "valid_data = TensorDataset(torch.from_numpy(np.array(valid_x)), torch.from_numpy(np.array(valid_y)))\n",
    "test_data = TensorDataset(torch.from_numpy(np.array(test_x)), torch.from_numpy(np.array(test_y)))\n",
    "# dataloaders\n",
    "batch_size = 32\n",
    "# make sure to SHUFFLE your data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_SingleProcessDataLoaderIter' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8402/200504455.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# obtain one batch of training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msample_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sample input size: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch_size, seq_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sample input: \\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_SingleProcessDataLoaderIter' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "train_on_gpu = False\n",
    "class SentimentLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid() # for outputs more than 1 Softmax()\n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # embeddings and lstm_out\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "    \n",
    "        # stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                        weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentLSTM(\n",
      "  (embedding): Embedding(97902, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding\n",
    "output_size = 1 # 3 for our case\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "net = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3... Step: 100... Loss: 0.692842... Val Loss: 0.692071\n",
      "Epoch: 1/3... Step: 200... Loss: 0.659829... Val Loss: 0.689900\n",
      "Epoch: 1/3... Step: 300... Loss: 0.685435... Val Loss: 0.690101\n",
      "Epoch: 1/3... Step: 400... Loss: 0.726474... Val Loss: 0.684682\n",
      "Epoch: 1/3... Step: 500... Loss: 0.667493... Val Loss: 0.683957\n",
      "Epoch: 1/3... Step: 600... Loss: 0.691564... Val Loss: 0.685495\n",
      "Epoch: 1/3... Step: 700... Loss: 0.707505... Val Loss: 0.682292\n",
      "Epoch: 1/3... Step: 800... Loss: 0.722550... Val Loss: 0.680156\n",
      "Epoch: 2/3... Step: 900... Loss: 0.590708... Val Loss: 0.710195\n",
      "Epoch: 2/3... Step: 1000... Loss: 0.637196... Val Loss: 0.715642\n",
      "Epoch: 2/3... Step: 1100... Loss: 0.674276... Val Loss: 0.736934\n",
      "Epoch: 2/3... Step: 1200... Loss: 0.626586... Val Loss: 0.731754\n",
      "Epoch: 2/3... Step: 1300... Loss: 0.617775... Val Loss: 0.756086\n",
      "Epoch: 2/3... Step: 1400... Loss: 0.666425... Val Loss: 0.715473\n",
      "Epoch: 2/3... Step: 1500... Loss: 0.717966... Val Loss: 0.726866\n",
      "Epoch: 2/3... Step: 1600... Loss: 0.640596... Val Loss: 0.726552\n",
      "Epoch: 3/3... Step: 1700... Loss: 0.470541... Val Loss: 0.918222\n",
      "Epoch: 3/3... Step: 1800... Loss: 0.447399... Val Loss: 0.998671\n",
      "Epoch: 3/3... Step: 1900... Loss: 0.288578... Val Loss: 0.971272\n",
      "Epoch: 3/3... Step: 2000... Loss: 0.599794... Val Loss: 0.986884\n",
      "Epoch: 3/3... Step: 2100... Loss: 0.502931... Val Loss: 0.984503\n",
      "Epoch: 3/3... Step: 2200... Loss: 0.356550... Val Loss: 0.973964\n",
      "Epoch: 3/3... Step: 2300... Loss: 0.292564... Val Loss: 0.950439\n",
      "Epoch: 3/3... Step: 2400... Loss: 0.359694... Val Loss: 1.002254\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss() # for more than one output CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "# training params\n",
    "\n",
    "epochs = 3 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
    "\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "# move model to GPU, if available\n",
    "# if(train_on_gpu):\n",
    "#     net.cuda()\n",
    "\n",
    "net.train()\n",
    "train_on_gpu=False\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        if train_on_gpu:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        inputs = inputs.type(torch.LongTensor)\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                # if(train_on_gpu):\n",
    "                #     inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                inputs = inputs.type(torch.LongTensor)\n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.021\n",
      "Test accuracy: 0.529\n"
     ]
    }
   ],
   "source": [
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "\n",
    "# init hidden state\n",
    "h = net.init_hidden(batch_size)\n",
    "\n",
    "net.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "\n",
    "    # Creating new variables for the hidden state, otherwise\n",
    "    # we'd backprop through the entire training history\n",
    "    h = tuple([each.data for each in h])\n",
    "\n",
    "    # if(train_on_gpu):\n",
    "    #     inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    \n",
    "    # get predicted outputs\n",
    "    inputs = inputs.type(torch.LongTensor)\n",
    "    output, h = net(inputs, h)\n",
    "    \n",
    "    # calculate loss\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) \n",
    "    np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "\n",
    "# -- stats! -- ##\n",
    "# avg test loss\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fed9591a510>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2312, 1, 47, 1855, 18, 1852]]\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0 2312    1\n",
      "    47 1855   18 1852]]\n",
      "torch.Size([1, 200])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from string import punctuation\n",
    "\n",
    "def tokenize_review(test_review):\n",
    "    test_review = test_review.lower() # lowercase\n",
    "    # get rid of punctuation\n",
    "    test_text = ''.join([c for c in test_review if c not in punctuation])\n",
    "\n",
    "    # splitting by spaces\n",
    "    test_words = test_text.split()\n",
    "\n",
    "    # tokens\n",
    "    test_ints = []\n",
    "    test_ints.append([vocab_to_int[word] for word in test_words])\n",
    "\n",
    "    return test_ints\n",
    "\n",
    "# test code and generate tokenized review\n",
    "test_ints = tokenize_review(\"ሙከራ ነው ይሄ ቢሰራ ደስ ይለኛል\")\n",
    "print(test_ints)\n",
    "\n",
    "\n",
    "# test sequence padding\n",
    "seq_length=200\n",
    "features = pad_features(test_ints, seq_length)\n",
    "\n",
    "print(features)\n",
    "\n",
    "\n",
    "# test conversion to tensor and pass into your model\n",
    "feature_tensor = torch.from_numpy(features)\n",
    "print(feature_tensor.size())\n",
    "\n",
    "\n",
    "def predict(net, test_review, sequence_length=200):\n",
    "    \n",
    "    net.eval()\n",
    "    \n",
    "    # tokenize review\n",
    "    test_ints = tokenize_review(test_review)\n",
    "    \n",
    "    # pad tokenized sequence\n",
    "    seq_length=sequence_length\n",
    "    features = pad_features(test_ints, seq_length)\n",
    "    \n",
    "    # convert to tensor to pass into your model\n",
    "    feature_tensor = torch.from_numpy(features)\n",
    "    \n",
    "    batch_size = feature_tensor.size(0)\n",
    "    \n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "    \n",
    "    if(train_on_gpu):\n",
    "        feature_tensor = feature_tensor.cuda()\n",
    "    \n",
    "    # get the output from the model\n",
    "    output, h = net(feature_tensor, h)\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze()) \n",
    "    # printing output value, before rounding\n",
    "    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
    "    \n",
    "    # print custom response\n",
    "    if(pred.item()==1):\n",
    "        print(\"Positive post detected!\")\n",
    "    else:\n",
    "        print(\"Negative post detected.\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction value, pre-rounding: 0.225311\n",
      "Negative review detected.\n"
     ]
    }
   ],
   "source": [
    "test_review = 'ትግራይና አማራ ይገደል ይሙት' #ጥቅም የለውምና ይጥፉ\n",
    "seq_length=200 \n",
    "predict(net, test_review, seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction value, pre-rounding: 0.921153\n",
      "Positive review detected!\n"
     ]
    }
   ],
   "source": [
    "test_review = 'ሙከራ ነው ይሄ ቢሰራ ደስ ይለኛል'\n",
    "seq_length=200 \n",
    "predict(net, test_review, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction value, pre-rounding: 0.232898\n",
      "Negative review detected.\n"
     ]
    }
   ],
   "source": [
    "test_review = 'ኢትዮጲያ አያስፈልግም'\n",
    "seq_length=200 \n",
    "predict(net, test_review, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction value, pre-rounding: 0.998828\n",
      "Positive review detected!\n"
     ]
    }
   ],
   "source": [
    "test_review = 'የሰላም እና የፍቅር አመት ይሁንልን'\n",
    "seq_length=200 \n",
    "predict(net, test_review, seq_length)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "matrix = CountVectorizer(analyzer='word',max_features=1000,ngram_range=(1, 3))\n",
    "X = matrix.fit_transform(new_ls2).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_label = list(set(labels))\n",
    "Y= []\n",
    "for i in labels:\n",
    "    Y.append(unique_label.index(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3871361338678752"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict Class\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e8b1f110ce6871e640b43de6ac4241768236fa0a81b3a9a2b5ddded4b10dd25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
