{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import emoji\n",
    "import sentencepiece as spm\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "import fasttext\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, BatchNormalization, Conv1D, MaxPooling1D, LSTM, SimpleRNN, Bidirectional, Dense, GlobalMaxPooling1D, Dropout,GRU, Input, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/70000correctly labled data.csv\")\n",
    "df = df[(df.sentiment != \"Neutral\") & (df.sentiment != \"labels\")]\n",
    "df.rename(columns={\"sentiment\":\"labels\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Negative', nan], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    24948\n",
       "Negative    20728\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_redu = df.copy()\n",
    "df_redu = df_redu.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = set(\n",
    "    \"\"\"\n",
    "ግን አንቺ አንተ እናንተ ያንተ ያንቺ የናንተ ራስህን ራስሽን ራሳችሁን\n",
    "ሁሉ ኋላ በሰሞኑ አሉ በኋላ ሁኔታ በኩል አስታውቀዋል ሆነ በውስጥ\n",
    "አስታውሰዋል ሆኑ ባጣም እስካሁን ሆኖም በተለይ አሳሰበ ሁል በተመለከተ\n",
    "አሳስበዋል ላይ በተመሳሳይ አስፈላጊ ሌላ የተለያየ አስገነዘቡ ሌሎች የተለያዩ\n",
    "አስገንዝበዋል ልዩ ተባለ አብራርተዋል መሆኑ ተገለጸ አስረድተዋል  ተገልጿል\n",
    "ማለቱ ተጨማሪ እባክህ የሚገኝ ተከናወነ እባክሽ ማድረግ ችግር አንጻር ማን\n",
    "ትናንት እስኪደርስ ነበረች እንኳ ሰሞኑን ነበሩ እንኳን ሲሆን ነበር እዚሁ ሲል\n",
    "ነው እንደገለጹት አለ ና እንደተናገሩት ቢሆን ነገር እንዳስረዱት ብለዋል ነገሮች\n",
    "እንደገና ብዙ ናት ወቅት ቦታ ናቸው እንዲሁም በርካታ አሁን እንጂ እስከ\n",
    "ማለት የሚሆኑት ስለማናቸውም ውስጥ ይሆናሉ ሲባል ከሆነው ስለዚሁ ከአንድ\n",
    "ያልሆነ ሳለ የነበረውን ከአንዳንድ በማናቸውም በሙሉ የሆነው ያሉ በእነዚሁ\n",
    "ወር መሆናቸው ከሌሎች በዋና አንዲት ወይም\n",
    "በላይ እንደ በማቀድ ለሌሎች በሆኑ ቢሆንም ጊዜና  ይሆኑበታል በሆነ አንዱ\n",
    "ለዚህ ለሆነው ለነዚህ ከዚህ የሌላውን ሶስተኛ አንዳንድ ለማንኛውም የሆነ ከሁለት\n",
    "የነገሩ ሰኣት አንደኛ እንዲሆን እንደነዚህ ማንኛውም ካልሆነ የሆኑት  ጋር ቢያንስ\n",
    "ይህንንም እነደሆነ እነዚህን ይኸው  የማናቸውም\n",
    "በሙሉም ይህችው በተለይም አንዱን የሚችለውን በነዚህ ከእነዚህ በሌላ\n",
    "የዚሁ ከእነዚሁ ለዚሁ በሚገባ ለእያንዳንዱ የአንቀጹ ወደ ይህም ስለሆነ ወይ\n",
    "ማናቸውንም ተብሎ እነዚህ መሆናቸውን የሆነችን ከአስር ሳይሆን ከዚያ የለውም\n",
    "የማይበልጥ እንደሆነና እንዲሆኑ  በሚችሉ ብቻ ብሎ ከሌላ የሌላቸውን\n",
    "ለሆነ በሌሎች ሁለቱንም በቀር ይህ በታች አንደሆነ በነሱ\n",
    "ይህን የሌላ እንዲህ ከሆነ ያላቸው በነዚሁ በሚል የዚህ ይህንኑ\n",
    "በእንደዚህ ቁጥር ማናቸውም ሆነው ባሉ በዚህ በስተቀር ሲሆንና\n",
    "በዚህም መሆን ምንጊዜም እነዚህም በዚህና ያለ ስም\n",
    "ሲኖር ከዚህም መሆኑን በሁኔታው የማያንስ እነዚህኑ ማንም ከነዚሁ\n",
    "ያላቸውን እጅግ ሲሆኑ ለሆኑ ሊሆን ለማናቸውም እና ነዉ\n",
    "\"\"\".split()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_redu.texts.values\n",
    "labels = df_redu.labels.values\n",
    "encoded_labels = []\n",
    "for label in labels:\n",
    "    if label == \"Negative\":\n",
    "        encoded_labels.append(0)\n",
    "    else:\n",
    "        encoded_labels.append(1)\n",
    "y = np.array(encoded_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "##### Steps Taken\n",
    "- filter stop wors\n",
    "- remove emojis\n",
    "- remove punc and special chars\n",
    "- remove ascii and numbers\n",
    "- normalize mogisha characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stop_words(ls):\n",
    "    new_ls_stop = []\n",
    "    for input in ls:\n",
    "        cleaned = [w for w in input.split(\" \") if not w in STOP_WORDS]\n",
    "        new_ls_stop.append(\" \".join(cleaned).strip())\n",
    "\n",
    "    return new_ls_stop\n",
    "    \n",
    "def remove_emojis(ls):\n",
    "    new_ls = []\n",
    "    for input in ls:\n",
    "        new_ls.append(emoji.replace_emoji(input)\n",
    ")\n",
    "    return new_ls\n",
    "    \n",
    "def remove_punc_and_special_chars(ls): \n",
    "    new_ls = []\n",
    "    for text in ls:\n",
    "        text = str(text)\n",
    "        text = re.sub('[፣]', ' ',text)\n",
    "        normalized_text = re.sub('[\\!\\@\\#\\$\\%\\^\\«\\»\\&\\*\\(\\)\\…\\[\\]\\{\\}\\;\\“\\”\\›\\’\\‘\\\"\\'\\:\\,\\.\\‹\\/\\<\\>\\?\\\\\\\\|\\`\\´\\~\\-\\=\\+\\፡\\።\\፤\\;\\፦\\፥\\፧\\፨\\፠\\፣]', '',text)\n",
    "        new_ls.append(normalized_text)\n",
    "    return new_ls\n",
    "\n",
    "def remove_ascii_and_numbers(ls):\n",
    "    new_ls = []\n",
    "    for text_input in ls:\n",
    "        text_input = str(text_input)\n",
    "        rm_num_and_ascii=re.sub('[A-Za-z0-9]','',text_input)\n",
    "        text = re.sub('[\\'\\u1369-\\u137C\\']+','',rm_num_and_ascii)\n",
    "        new_ls.append(text)\n",
    "    return new_ls\n",
    "\n",
    "def normalize_char_level_missmatch(ls):\n",
    "        new_ls = []\n",
    "        for input_token in ls:\n",
    "                input_token = str(input_token)\n",
    "                rep1=re.sub('[ሃኅኃሐሓኻ]','ሀ',input_token)\n",
    "                rep2=re.sub('[ሑኁዅ]','ሁ',rep1)\n",
    "                rep3=re.sub('[ኂሒኺ]','ሂ',rep2)\n",
    "                rep4=re.sub('[ኌሔዄ]','ሄ',rep3)\n",
    "                rep5=re.sub('[ሕኅ]','ህ',rep4)\n",
    "                rep6=re.sub('[ኆሖኾ]','ሆ',rep5)\n",
    "                rep7=re.sub('[ሠ]','ሰ',rep6)\n",
    "                rep8=re.sub('[ሡ]','ሱ',rep7)\n",
    "                rep9=re.sub('[ሢ]','ሲ',rep8)\n",
    "                rep10=re.sub('[ሣ]','ሳ',rep9)\n",
    "                rep11=re.sub('[ሤ]','ሴ',rep10)\n",
    "                rep12=re.sub('[ሥ]','ስ',rep11)\n",
    "                rep13=re.sub('[ሦ]','ሶ',rep12)\n",
    "                rep14=re.sub('[ዓኣዐ]','አ',rep13)\n",
    "                rep15=re.sub('[ዑ]','ኡ',rep14)\n",
    "                rep16=re.sub('[ዒ]','ኢ',rep15)\n",
    "                rep17=re.sub('[ዔ]','ኤ',rep16)\n",
    "                rep18=re.sub('[ዕ]','እ',rep17)\n",
    "                rep19=re.sub('[ዖ]','ኦ',rep18)\n",
    "                rep20=re.sub('[ጸ]','ፀ',rep19)\n",
    "                rep21=re.sub('[ጹ]','ፁ',rep20)\n",
    "                rep22=re.sub('[ጺ]','ፂ',rep21)\n",
    "                rep23=re.sub('[ጻ]','ፃ',rep22)\n",
    "                rep24=re.sub('[ጼ]','ፄ',rep23)\n",
    "                rep25=re.sub('[ጽ]','ፅ',rep24)\n",
    "                rep26=re.sub('[ጾ]','ፆ',rep25)\n",
    "                #Normalizing words with Labialized Amharic characters such as በልቱዋል or  በልቱአል to  በልቷል  \n",
    "                rep27=re.sub('(ሉ[ዋአ])','ሏ',rep26)\n",
    "                rep28=re.sub('(ሙ[ዋአ])','ሟ',rep27)\n",
    "                rep29=re.sub('(ቱ[ዋአ])','ቷ',rep28)\n",
    "                rep30=re.sub('(ሩ[ዋአ])','ሯ',rep29)\n",
    "                rep31=re.sub('(ሱ[ዋአ])','ሷ',rep30)\n",
    "                rep32=re.sub('(ሹ[ዋአ])','ሿ',rep31)\n",
    "                rep33=re.sub('(ቁ[ዋአ])','ቋ',rep32)\n",
    "                rep34=re.sub('(ቡ[ዋአ])','ቧ',rep33)\n",
    "                rep35=re.sub('(ቹ[ዋአ])','ቿ',rep34)\n",
    "                rep36=re.sub('(ሁ[ዋአ])','ኋ',rep35)\n",
    "                rep37=re.sub('(ኑ[ዋአ])','ኗ',rep36)\n",
    "                rep38=re.sub('(ኙ[ዋአ])','ኟ',rep37)\n",
    "                rep39=re.sub('(ኩ[ዋአ])','ኳ',rep38)\n",
    "                rep40=re.sub('(ዙ[ዋአ])','ዟ',rep39)\n",
    "                rep41=re.sub('(ጉ[ዋአ])','ጓ',rep40)\n",
    "                rep42=re.sub('(ደ[ዋአ])','ዷ',rep41)\n",
    "                rep43=re.sub('(ጡ[ዋአ])','ጧ',rep42)\n",
    "                rep44=re.sub('(ጩ[ዋአ])','ጯ',rep43)\n",
    "                rep45=re.sub('(ጹ[ዋአ])','ጿ',rep44)\n",
    "                rep46=re.sub('(ፉ[ዋአ])','ፏ',rep45)\n",
    "                rep47=re.sub('[ቊ]','ቁ',rep46) #ቁ can be written as ቊ\n",
    "                rep48=re.sub('[ኵ]','ኩ',rep47) #ኩ can be also written as ኵ  \n",
    "                new_ls.append(rep48)\n",
    "        return new_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46553"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = normalize_char_level_missmatch(X)\n",
    "X = remove_punc_and_special_chars(X)\n",
    "X = remove_ascii_and_numbers(X)\n",
    "X = remove_emojis(X)\n",
    "X = filter_stop_words(X)\n",
    "\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Spliting the data to 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tokenizing the data (this is a very important stage and depends on the tokeinzer especiall for a langugage in amharic)\n",
    "- padding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = True\n",
    "if token == True:\n",
    "    tokenizer = Tokenizer(num_words=50000)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    X_train = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "else:\n",
    "    sp = spm.SentencePieceProcessor()\n",
    "    sp.Load(\"../embeddings/amh_sp.model\")\n",
    "\n",
    "    # sp.EncodeAsPieces(X[1])\n",
    "    X_train = sp.EncodeAsIds(X_train)\n",
    "    X_test = sp.EncodeAsIds(X_test)\n",
    "\n",
    "    vocab_size = sp.GetPieceSize() + 1\n",
    "\n",
    "\n",
    "maxlen = 10\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37242"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37242"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[:40000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9311"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepartion for Trainning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implement early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # monitor both validation loss and validation accuracy\n",
    "    mode='min',          # stop training when the quantity monitored has stopped decreasing\n",
    "    patience=5,          # number of epochs with no improvement after which training will be stopped\n",
    "    verbose=1,\n",
    "    restore_best_weights=True  # restore the weights from the epoch with the best value of the monitored quantity\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- adding embeddings using fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "## fast text word embedding\n",
    "word_vectors = fasttext.load_model(\"cc.am.100.bin\")\n",
    "\n",
    "# Define the maximum number of words to keep\n",
    "max_words = 50000\n",
    "\n",
    "# Extract the embedding matrix from the FastText model\n",
    "embedding_dim = word_vectors.get_dimension()\n",
    "word_index = tokenizer.word_index\n",
    "num_words = min(max_words, len(word_index)) + 1\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_words:\n",
    "        continue\n",
    "    if word in word_vectors:\n",
    "        embedding_matrix[i] = word_vectors[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 16:18:36.067013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-20 16:18:36.178151: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /u01/app/oracle/product/11.2.0/xe/lib:\n",
      "2023-05-20 16:18:36.178191: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-20 16:18:36.180967: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-20 16:18:36.206268: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 20000400 exceeds 10% of free system memory.\n",
      "2023-05-20 16:18:36.217455: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 20000400 exceeds 10% of free system memory.\n",
      "2023-05-20 16:18:36.221106: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 20000400 exceeds 10% of free system memory.\n",
      "2023-05-20 16:18:36.238111: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 20000400 exceeds 10% of free system memory.\n",
      "2023-05-20 16:18:36.290430: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 20000400 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the deep learning models\n",
    "models = [\n",
    "    {\n",
    "        'name': 'CNN',\n",
    "        'model': Sequential([\n",
    "            (Embedding(max_words + 1,\n",
    "                    embedding_dim,\n",
    "                    embeddings_initializer='glorot_uniform',\n",
    "                    input_length=maxlen,\n",
    "                    weights=[embedding_matrix],\n",
    "                    trainable=False)),\n",
    "            Conv1D(32, 5, activation='relu'),\n",
    "            GlobalMaxPooling1D(),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "    },\n",
    "    {\n",
    "        'name': 'RNN',\n",
    "        'model': Sequential([\n",
    "            (Embedding(max_words + 1,\n",
    "                    embedding_dim,\n",
    "                    embeddings_initializer='glorot_uniform',\n",
    "                    input_length=maxlen,\n",
    "                    weights=[embedding_matrix],\n",
    "                    trainable=False)),\n",
    "            SimpleRNN(32, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01)),\n",
    "            BatchNormalization(),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "    },\n",
    "    {\n",
    "        'name': 'LSTM',\n",
    "        'model': Sequential([\n",
    "            (Embedding(max_words + 1,\n",
    "                    embedding_dim,\n",
    "                    embeddings_initializer='glorot_uniform',\n",
    "                    input_length=maxlen,\n",
    "                    weights=[embedding_matrix],\n",
    "                    trainable=False)),\n",
    "            LSTM(32, activation='relu'),\n",
    "            Dense(64, activation='sigmoid'),\n",
    "            Dropout(0.5),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(1, activation='sigmoid')\n",
    "            \n",
    "        ])\n",
    "    },\n",
    "    {\n",
    "        'name': 'bi-LSTM',\n",
    "        'model': Sequential([\n",
    "            (Embedding(max_words + 1,\n",
    "                    embedding_dim,\n",
    "                    embeddings_initializer='glorot_uniform',\n",
    "                    input_length=maxlen,\n",
    "                    weights=[embedding_matrix],\n",
    "                    trainable=False)),\n",
    "            Bidirectional(LSTM(32, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), dropout=0.2, recurrent_dropout=0.2)),\n",
    "            Dense(32, activation='sigmoid'),\n",
    "            Dropout(0.5),\n",
    "            Dense(1, activation='sigmoid')\n",
    "            \n",
    "        ])\n",
    "    },\n",
    "    {\n",
    "        'name': 'GRU',\n",
    "        'model': Sequential([\n",
    "            (Embedding(max_words + 1,\n",
    "                    embedding_dim,\n",
    "                    embeddings_initializer='glorot_uniform',\n",
    "                    input_length=maxlen,\n",
    "                    weights=[embedding_matrix],\n",
    "                    trainable=False)),\n",
    "            GRU(units=32, dropout=0.2, recurrent_dropout=0.2),\n",
    "            Dense(1, activation='sigmoid')           \n",
    "        ])\n",
    "    }\n",
    "\n",
    "   \n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile each model\n",
    "for m in models:\n",
    "    m['model'].compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.3143 - accuracy: 0.8810 - val_loss: 0.5066 - val_accuracy: 0.7703\n",
      "Epoch 2/80\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.2928 - accuracy: 0.8886 - val_loss: 0.5194 - val_accuracy: 0.7681\n",
      "Epoch 3/80\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.2787 - accuracy: 0.8938 - val_loss: 0.5309 - val_accuracy: 0.7660\n",
      "Epoch 4/80\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.2619 - accuracy: 0.9016 - val_loss: 0.5454 - val_accuracy: 0.7673\n",
      "Epoch 5/80\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.2535 - accuracy: 0.9074 - val_loss: 0.5548 - val_accuracy: 0.7665\n",
      "Epoch 6/80\n",
      "146/157 [==========================>...] - ETA: 0s - loss: 0.2457 - accuracy: 0.9114Restoring model weights from the end of the best epoch: 1.\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.2419 - accuracy: 0.9134 - val_loss: 0.5687 - val_accuracy: 0.7657\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/80\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.5324 - accuracy: 0.7386 - val_loss: 0.5470 - val_accuracy: 0.7344\n",
      "Epoch 2/80\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.5251 - accuracy: 0.7488 - val_loss: 0.5558 - val_accuracy: 0.7244\n",
      "Epoch 3/80\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.5210 - accuracy: 0.7482 - val_loss: 0.5591 - val_accuracy: 0.7197\n",
      "Epoch 4/80\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.5175 - accuracy: 0.7576 - val_loss: 0.5507 - val_accuracy: 0.7349\n",
      "Epoch 5/80\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.5144 - accuracy: 0.7558 - val_loss: 0.5490 - val_accuracy: 0.7415\n",
      "Epoch 6/80\n",
      "150/157 [===========================>..] - ETA: 0s - loss: 0.5162 - accuracy: 0.7542Restoring model weights from the end of the best epoch: 1.\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.5133 - accuracy: 0.7560 - val_loss: 0.5510 - val_accuracy: 0.7420\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/80\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.3491 - accuracy: 0.8564 - val_loss: 0.4349 - val_accuracy: 0.8013\n",
      "Epoch 2/80\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.3368 - accuracy: 0.8642 - val_loss: 0.4411 - val_accuracy: 0.7998\n",
      "Epoch 3/80\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.3346 - accuracy: 0.8630 - val_loss: 0.4547 - val_accuracy: 0.7919\n",
      "Epoch 4/80\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3259 - accuracy: 0.8650 - val_loss: 0.4691 - val_accuracy: 0.7876\n",
      "Epoch 5/80\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.3256 - accuracy: 0.8670 - val_loss: 0.4526 - val_accuracy: 0.7965\n",
      "Epoch 6/80\n",
      "149/157 [===========================>..] - ETA: 0s - loss: 0.3232 - accuracy: 0.8670Restoring model weights from the end of the best epoch: 1.\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3219 - accuracy: 0.8682 - val_loss: 0.4546 - val_accuracy: 0.7971\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/80\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 0.5458 - accuracy: 0.7270 - val_loss: 0.5350 - val_accuracy: 0.7327\n",
      "Epoch 2/80\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 0.5441 - accuracy: 0.7258 - val_loss: 0.5441 - val_accuracy: 0.7268\n",
      "Epoch 3/80\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 0.5406 - accuracy: 0.7346 - val_loss: 0.5358 - val_accuracy: 0.7358\n",
      "Epoch 4/80\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 0.5459 - accuracy: 0.7238 - val_loss: 0.5429 - val_accuracy: 0.7276\n",
      "Epoch 5/80\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 0.5445 - accuracy: 0.7352 - val_loss: 0.5373 - val_accuracy: 0.7342\n",
      "Epoch 6/80\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.5479 - accuracy: 0.7328Restoring model weights from the end of the best epoch: 1.\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 0.5479 - accuracy: 0.7328 - val_loss: 0.5375 - val_accuracy: 0.7336\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/80\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4057 - accuracy: 0.8100 - val_loss: 0.4203 - val_accuracy: 0.8069\n",
      "Epoch 2/80\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4069 - accuracy: 0.8176 - val_loss: 0.4228 - val_accuracy: 0.8050\n",
      "Epoch 3/80\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.4016 - accuracy: 0.8172 - val_loss: 0.4210 - val_accuracy: 0.8071\n",
      "Epoch 4/80\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.3955 - accuracy: 0.8160 - val_loss: 0.4221 - val_accuracy: 0.8075\n",
      "Epoch 5/80\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.3975 - accuracy: 0.8164 - val_loss: 0.4211 - val_accuracy: 0.8075\n",
      "Epoch 6/80\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.3959 - accuracy: 0.8205Restoring model weights from the end of the best epoch: 1.\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.3962 - accuracy: 0.8202 - val_loss: 0.4211 - val_accuracy: 0.8045\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/80\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3386 - accuracy: 0.8610 - val_loss: 0.5176 - val_accuracy: 0.7653\n",
      "Epoch 2/80\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3239 - accuracy: 0.8700 - val_loss: 0.5260 - val_accuracy: 0.7650\n",
      "Epoch 3/80\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3104 - accuracy: 0.8763 - val_loss: 0.5375 - val_accuracy: 0.7651\n",
      "Epoch 4/80\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2987 - accuracy: 0.8809 - val_loss: 0.5470 - val_accuracy: 0.7639\n",
      "Epoch 5/80\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2813 - accuracy: 0.8920 - val_loss: 0.5651 - val_accuracy: 0.7646\n",
      "Epoch 6/80\n",
      "299/313 [===========================>..] - ETA: 0s - loss: 0.2659 - accuracy: 0.9006Restoring model weights from the end of the best epoch: 1.\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2679 - accuracy: 0.9000 - val_loss: 0.5746 - val_accuracy: 0.7606\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/80\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.5275 - accuracy: 0.7454 - val_loss: 0.5486 - val_accuracy: 0.7431\n",
      "Epoch 2/80\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.5265 - accuracy: 0.7439 - val_loss: 0.5480 - val_accuracy: 0.7399\n",
      "Epoch 3/80\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.5263 - accuracy: 0.7484 - val_loss: 0.5474 - val_accuracy: 0.7341\n",
      "Epoch 4/80\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.5232 - accuracy: 0.7508 - val_loss: 0.5479 - val_accuracy: 0.7344\n",
      "Epoch 5/80\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.5249 - accuracy: 0.7444 - val_loss: 0.5519 - val_accuracy: 0.7391\n",
      "Epoch 6/80\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.5205 - accuracy: 0.7530 - val_loss: 0.5520 - val_accuracy: 0.7434\n",
      "Epoch 7/80\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.5210 - accuracy: 0.7514 - val_loss: 0.5554 - val_accuracy: 0.7402\n",
      "Epoch 8/80\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.5200 - accuracy: 0.7508Restoring model weights from the end of the best epoch: 3.\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.5199 - accuracy: 0.7507 - val_loss: 0.5499 - val_accuracy: 0.7330\n",
      "Epoch 8: early stopping\n",
      "Epoch 1/80\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3470 - accuracy: 0.8553 - val_loss: 0.4402 - val_accuracy: 0.8007\n",
      "Epoch 2/80\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3428 - accuracy: 0.8575 - val_loss: 0.4452 - val_accuracy: 0.7977\n",
      "Epoch 3/80\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3393 - accuracy: 0.8594 - val_loss: 0.4435 - val_accuracy: 0.7983\n",
      "Epoch 4/80\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3402 - accuracy: 0.8591 - val_loss: 0.4436 - val_accuracy: 0.8002\n",
      "Epoch 5/80\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3361 - accuracy: 0.8603 - val_loss: 0.4474 - val_accuracy: 0.7989\n",
      "Epoch 6/80\n",
      "306/313 [============================>.] - ETA: 0s - loss: 0.3372 - accuracy: 0.8623Restoring model weights from the end of the best epoch: 1.\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3379 - accuracy: 0.8619 - val_loss: 0.4457 - val_accuracy: 0.7986\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/80\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.5448 - accuracy: 0.7292 - val_loss: 0.5347 - val_accuracy: 0.7307\n",
      "Epoch 2/80\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.5480 - accuracy: 0.7281 - val_loss: 0.5350 - val_accuracy: 0.7359\n",
      "Epoch 3/80\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.5475 - accuracy: 0.7293 - val_loss: 0.5374 - val_accuracy: 0.7299\n",
      "Epoch 4/80\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.5478 - accuracy: 0.7252 - val_loss: 0.5359 - val_accuracy: 0.7344\n",
      "Epoch 5/80\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.5461 - accuracy: 0.7287 - val_loss: 0.5370 - val_accuracy: 0.7350\n",
      "Epoch 6/80\n",
      "309/313 [============================>.] - ETA: 0s - loss: 0.5453 - accuracy: 0.7309Restoring model weights from the end of the best epoch: 1.\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.5453 - accuracy: 0.7312 - val_loss: 0.5378 - val_accuracy: 0.7323\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/80\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.4072 - accuracy: 0.8123 - val_loss: 0.4188 - val_accuracy: 0.8058\n",
      "Epoch 2/80\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.4046 - accuracy: 0.8162 - val_loss: 0.4196 - val_accuracy: 0.8066\n",
      "Epoch 3/80\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.4034 - accuracy: 0.8155 - val_loss: 0.4198 - val_accuracy: 0.8061\n",
      "Epoch 4/80\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.4047 - accuracy: 0.8122 - val_loss: 0.4202 - val_accuracy: 0.8081\n",
      "Epoch 5/80\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.4031 - accuracy: 0.8129 - val_loss: 0.4193 - val_accuracy: 0.8075\n",
      "Epoch 6/80\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.4026 - accuracy: 0.8180Restoring model weights from the end of the best epoch: 1.\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.4031 - accuracy: 0.8176 - val_loss: 0.4196 - val_accuracy: 0.8075\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/80\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3546 - accuracy: 0.8495 - val_loss: 0.5206 - val_accuracy: 0.7665\n",
      "Epoch 2/80\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3446 - accuracy: 0.8569 - val_loss: 0.5322 - val_accuracy: 0.7654\n",
      "Epoch 3/80\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3354 - accuracy: 0.8667 - val_loss: 0.5347 - val_accuracy: 0.7637\n",
      "Epoch 4/80\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3206 - accuracy: 0.8712 - val_loss: 0.5454 - val_accuracy: 0.7629\n",
      "Epoch 5/80\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3132 - accuracy: 0.8753 - val_loss: 0.5556 - val_accuracy: 0.7641\n",
      "Epoch 6/80\n",
      "444/469 [===========================>..] - ETA: 0s - loss: 0.2963 - accuracy: 0.8839Restoring model weights from the end of the best epoch: 1.\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2981 - accuracy: 0.8828 - val_loss: 0.5716 - val_accuracy: 0.7631\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/80\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5349 - accuracy: 0.7443 - val_loss: 0.5562 - val_accuracy: 0.7314\n",
      "Epoch 2/80\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5315 - accuracy: 0.7467 - val_loss: 0.5481 - val_accuracy: 0.7434\n",
      "Epoch 3/80\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5302 - accuracy: 0.7468 - val_loss: 0.5458 - val_accuracy: 0.7373\n",
      "Epoch 4/80\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5288 - accuracy: 0.7495 - val_loss: 0.5452 - val_accuracy: 0.7404\n",
      "Epoch 5/80\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5285 - accuracy: 0.7496 - val_loss: 0.5499 - val_accuracy: 0.7422\n",
      "Epoch 6/80\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5307 - accuracy: 0.7496 - val_loss: 0.5585 - val_accuracy: 0.7296\n",
      "Epoch 7/80\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5281 - accuracy: 0.7497 - val_loss: 0.5541 - val_accuracy: 0.7446\n",
      "Epoch 8/80\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5268 - accuracy: 0.7453 - val_loss: 0.5505 - val_accuracy: 0.7363\n",
      "Epoch 9/80\n",
      "463/469 [============================>.] - ETA: 0s - loss: 0.5260 - accuracy: 0.7499Restoring model weights from the end of the best epoch: 4.\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5269 - accuracy: 0.7495 - val_loss: 0.5462 - val_accuracy: 0.7440\n",
      "Epoch 9: early stopping\n",
      "Epoch 1/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.3561 - accuracy: 0.8514 - val_loss: 0.4441 - val_accuracy: 0.7982\n",
      "Epoch 2/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.3514 - accuracy: 0.8511 - val_loss: 0.4384 - val_accuracy: 0.8005\n",
      "Epoch 3/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.3483 - accuracy: 0.8537 - val_loss: 0.4417 - val_accuracy: 0.7995\n",
      "Epoch 4/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.3479 - accuracy: 0.8545 - val_loss: 0.4397 - val_accuracy: 0.8018\n",
      "Epoch 5/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.3461 - accuracy: 0.8561 - val_loss: 0.4411 - val_accuracy: 0.8001\n",
      "Epoch 6/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.3451 - accuracy: 0.8560 - val_loss: 0.4415 - val_accuracy: 0.7994\n",
      "Epoch 7/80\n",
      "467/469 [============================>.] - ETA: 0s - loss: 0.3403 - accuracy: 0.8599Restoring model weights from the end of the best epoch: 2.\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.3405 - accuracy: 0.8599 - val_loss: 0.4479 - val_accuracy: 0.8003\n",
      "Epoch 7: early stopping\n",
      "Epoch 1/80\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.5508 - accuracy: 0.7294 - val_loss: 0.5350 - val_accuracy: 0.7333\n",
      "Epoch 2/80\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.5531 - accuracy: 0.7255 - val_loss: 0.5358 - val_accuracy: 0.7344\n",
      "Epoch 3/80\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.5544 - accuracy: 0.7262 - val_loss: 0.5351 - val_accuracy: 0.7354\n",
      "Epoch 4/80\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.5519 - accuracy: 0.7252 - val_loss: 0.5365 - val_accuracy: 0.7301\n",
      "Epoch 5/80\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.5524 - accuracy: 0.7223 - val_loss: 0.5360 - val_accuracy: 0.7302\n",
      "Epoch 6/80\n",
      "466/469 [============================>.] - ETA: 0s - loss: 0.5497 - accuracy: 0.7264Restoring model weights from the end of the best epoch: 1.\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.5500 - accuracy: 0.7263 - val_loss: 0.5355 - val_accuracy: 0.7350\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/80\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4093 - accuracy: 0.8127 - val_loss: 0.4191 - val_accuracy: 0.8053\n",
      "Epoch 2/80\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4107 - accuracy: 0.8145 - val_loss: 0.4190 - val_accuracy: 0.8064\n",
      "Epoch 3/80\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4084 - accuracy: 0.8150 - val_loss: 0.4202 - val_accuracy: 0.8072\n",
      "Epoch 4/80\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4113 - accuracy: 0.8133 - val_loss: 0.4192 - val_accuracy: 0.8069\n",
      "Epoch 5/80\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4072 - accuracy: 0.8133 - val_loss: 0.4206 - val_accuracy: 0.8069\n",
      "Epoch 6/80\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4087 - accuracy: 0.8119 - val_loss: 0.4250 - val_accuracy: 0.8043\n",
      "Epoch 7/80\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4069 - accuracy: 0.8139 - val_loss: 0.4187 - val_accuracy: 0.8061\n",
      "Epoch 8/80\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4076 - accuracy: 0.8124 - val_loss: 0.4186 - val_accuracy: 0.8047\n",
      "Epoch 9/80\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4058 - accuracy: 0.8143 - val_loss: 0.4210 - val_accuracy: 0.8061\n",
      "Epoch 10/80\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4045 - accuracy: 0.8163 - val_loss: 0.4192 - val_accuracy: 0.8069\n",
      "Epoch 11/80\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4040 - accuracy: 0.8157 - val_loss: 0.4195 - val_accuracy: 0.8068\n",
      "Epoch 12/80\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.4042 - accuracy: 0.8139 - val_loss: 0.4191 - val_accuracy: 0.8050\n",
      "Epoch 13/80\n",
      "460/469 [============================>.] - ETA: 0s - loss: 0.4040 - accuracy: 0.8165Restoring model weights from the end of the best epoch: 8.\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4040 - accuracy: 0.8161 - val_loss: 0.4198 - val_accuracy: 0.8060\n",
      "Epoch 13: early stopping\n",
      "Epoch 1/80\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.3671 - accuracy: 0.8465 - val_loss: 0.5161 - val_accuracy: 0.7654\n",
      "Epoch 2/80\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.3582 - accuracy: 0.8505 - val_loss: 0.5241 - val_accuracy: 0.7649\n",
      "Epoch 3/80\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.3497 - accuracy: 0.8551 - val_loss: 0.5305 - val_accuracy: 0.7645\n",
      "Epoch 4/80\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.3386 - accuracy: 0.8617 - val_loss: 0.5361 - val_accuracy: 0.7633\n",
      "Epoch 5/80\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.3291 - accuracy: 0.8673 - val_loss: 0.5465 - val_accuracy: 0.7605\n",
      "Epoch 6/80\n",
      "603/625 [===========================>..] - ETA: 0s - loss: 0.3189 - accuracy: 0.8705Restoring model weights from the end of the best epoch: 1.\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.3186 - accuracy: 0.8709 - val_loss: 0.5565 - val_accuracy: 0.7609\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/80\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.5349 - accuracy: 0.7454 - val_loss: 0.5457 - val_accuracy: 0.7384\n",
      "Epoch 2/80\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.5330 - accuracy: 0.7458 - val_loss: 0.5502 - val_accuracy: 0.7382\n",
      "Epoch 3/80\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.5301 - accuracy: 0.7472 - val_loss: 0.5487 - val_accuracy: 0.7339\n",
      "Epoch 4/80\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.5341 - accuracy: 0.7484 - val_loss: 0.5512 - val_accuracy: 0.7405\n",
      "Epoch 5/80\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.5324 - accuracy: 0.7449 - val_loss: 0.5437 - val_accuracy: 0.7377\n",
      "Epoch 6/80\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.5314 - accuracy: 0.7468 - val_loss: 0.5511 - val_accuracy: 0.7441\n",
      "Epoch 7/80\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.5304 - accuracy: 0.7472 - val_loss: 0.5484 - val_accuracy: 0.7377\n",
      "Epoch 8/80\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.5307 - accuracy: 0.7478 - val_loss: 0.5510 - val_accuracy: 0.7421\n",
      "Epoch 9/80\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.5306 - accuracy: 0.7476 - val_loss: 0.5622 - val_accuracy: 0.7388\n",
      "Epoch 10/80\n",
      "622/625 [============================>.] - ETA: 0s - loss: 0.5317 - accuracy: 0.7477Restoring model weights from the end of the best epoch: 5.\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.5316 - accuracy: 0.7474 - val_loss: 0.5497 - val_accuracy: 0.7371\n",
      "Epoch 10: early stopping\n",
      "Epoch 1/80\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.3541 - accuracy: 0.8512 - val_loss: 0.4509 - val_accuracy: 0.7920\n",
      "Epoch 2/80\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.3534 - accuracy: 0.8527 - val_loss: 0.4420 - val_accuracy: 0.8000\n",
      "Epoch 3/80\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.3531 - accuracy: 0.8519 - val_loss: 0.4489 - val_accuracy: 0.7984\n",
      "Epoch 4/80\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.3516 - accuracy: 0.8536 - val_loss: 0.4434 - val_accuracy: 0.7984\n",
      "Epoch 5/80\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.3472 - accuracy: 0.8563 - val_loss: 0.4446 - val_accuracy: 0.7995\n",
      "Epoch 6/80\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.3492 - accuracy: 0.8540 - val_loss: 0.4484 - val_accuracy: 0.7968\n",
      "Epoch 7/80\n",
      "616/625 [============================>.] - ETA: 0s - loss: 0.3478 - accuracy: 0.8565Restoring model weights from the end of the best epoch: 2.\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.3481 - accuracy: 0.8562 - val_loss: 0.4433 - val_accuracy: 0.7991\n",
      "Epoch 7: early stopping\n",
      "Epoch 1/80\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.5512 - accuracy: 0.7261 - val_loss: 0.5358 - val_accuracy: 0.7338\n",
      "Epoch 2/80\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.5476 - accuracy: 0.7300 - val_loss: 0.5345 - val_accuracy: 0.7348\n",
      "Epoch 3/80\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.5505 - accuracy: 0.7262 - val_loss: 0.5355 - val_accuracy: 0.7324\n",
      "Epoch 4/80\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.5499 - accuracy: 0.7275 - val_loss: 0.5354 - val_accuracy: 0.7362\n",
      "Epoch 5/80\n",
      "625/625 [==============================] - 7s 10ms/step - loss: 0.5488 - accuracy: 0.7239 - val_loss: 0.5345 - val_accuracy: 0.7318\n",
      "Epoch 6/80\n",
      "625/625 [==============================] - 7s 10ms/step - loss: 0.5488 - accuracy: 0.7272 - val_loss: 0.5347 - val_accuracy: 0.7357\n",
      "Epoch 7/80\n",
      "622/625 [============================>.] - ETA: 0s - loss: 0.5501 - accuracy: 0.7281Restoring model weights from the end of the best epoch: 2.\n",
      "625/625 [==============================] - 7s 10ms/step - loss: 0.5504 - accuracy: 0.7279 - val_loss: 0.5355 - val_accuracy: 0.7315\n",
      "Epoch 7: early stopping\n",
      "Epoch 1/80\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.4047 - accuracy: 0.8163 - val_loss: 0.4189 - val_accuracy: 0.8063\n",
      "Epoch 2/80\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.4078 - accuracy: 0.8151 - val_loss: 0.4191 - val_accuracy: 0.8055\n",
      "Epoch 3/80\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.4080 - accuracy: 0.8117 - val_loss: 0.4191 - val_accuracy: 0.8068\n",
      "Epoch 4/80\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.4081 - accuracy: 0.8169 - val_loss: 0.4192 - val_accuracy: 0.8067\n",
      "Epoch 5/80\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.4050 - accuracy: 0.8160 - val_loss: 0.4195 - val_accuracy: 0.8066\n",
      "Epoch 6/80\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.4084 - accuracy: 0.8129 - val_loss: 0.4183 - val_accuracy: 0.8068\n",
      "Epoch 7/80\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.4094 - accuracy: 0.8114 - val_loss: 0.4183 - val_accuracy: 0.8058\n",
      "Epoch 8/80\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.4075 - accuracy: 0.8102 - val_loss: 0.4182 - val_accuracy: 0.8069\n",
      "Epoch 9/80\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.4034 - accuracy: 0.8171 - val_loss: 0.4202 - val_accuracy: 0.8070\n",
      "Epoch 10/80\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.4064 - accuracy: 0.8141 - val_loss: 0.4196 - val_accuracy: 0.8063\n",
      "Epoch 11/80\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.4026 - accuracy: 0.8188 - val_loss: 0.4181 - val_accuracy: 0.8080\n",
      "Epoch 12/80\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.4039 - accuracy: 0.8162 - val_loss: 0.4190 - val_accuracy: 0.8053\n",
      "Epoch 13/80\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.4036 - accuracy: 0.8159 - val_loss: 0.4194 - val_accuracy: 0.8070\n",
      "Epoch 14/80\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.4048 - accuracy: 0.8156 - val_loss: 0.4185 - val_accuracy: 0.8079\n",
      "Epoch 15/80\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.4011 - accuracy: 0.8181 - val_loss: 0.4194 - val_accuracy: 0.8069\n",
      "Epoch 16/80\n",
      "618/625 [============================>.] - ETA: 0s - loss: 0.4032 - accuracy: 0.8180Restoring model weights from the end of the best epoch: 11.\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.4026 - accuracy: 0.8185 - val_loss: 0.4195 - val_accuracy: 0.8067\n",
      "Epoch 16: early stopping\n",
      "Epoch 1/80\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3788 - accuracy: 0.8401 - val_loss: 0.5137 - val_accuracy: 0.7673\n",
      "Epoch 2/80\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3678 - accuracy: 0.8467 - val_loss: 0.5165 - val_accuracy: 0.7660\n",
      "Epoch 3/80\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3594 - accuracy: 0.8496 - val_loss: 0.5227 - val_accuracy: 0.7603\n",
      "Epoch 4/80\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3494 - accuracy: 0.8560 - val_loss: 0.5294 - val_accuracy: 0.7625\n",
      "Epoch 5/80\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3402 - accuracy: 0.8613 - val_loss: 0.5345 - val_accuracy: 0.7647\n",
      "Epoch 6/80\n",
      "780/782 [============================>.] - ETA: 0s - loss: 0.3299 - accuracy: 0.8669Restoring model weights from the end of the best epoch: 1.\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3299 - accuracy: 0.8670 - val_loss: 0.5453 - val_accuracy: 0.7657\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/80\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.5308 - accuracy: 0.7472 - val_loss: 0.5474 - val_accuracy: 0.7411\n",
      "Epoch 2/80\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.5285 - accuracy: 0.7454 - val_loss: 0.5413 - val_accuracy: 0.7387\n",
      "Epoch 3/80\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.5302 - accuracy: 0.7493 - val_loss: 0.5587 - val_accuracy: 0.7352\n",
      "Epoch 4/80\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.5297 - accuracy: 0.7478 - val_loss: 0.5494 - val_accuracy: 0.7427\n",
      "Epoch 5/80\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.5280 - accuracy: 0.7488 - val_loss: 0.5508 - val_accuracy: 0.7362\n",
      "Epoch 6/80\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.5280 - accuracy: 0.7472 - val_loss: 0.5500 - val_accuracy: 0.7361\n",
      "Epoch 7/80\n",
      "779/782 [============================>.] - ETA: 0s - loss: 0.5273 - accuracy: 0.7489Restoring model weights from the end of the best epoch: 2.\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.5273 - accuracy: 0.7492 - val_loss: 0.5516 - val_accuracy: 0.7410\n",
      "Epoch 7: early stopping\n",
      "Epoch 1/80\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3590 - accuracy: 0.8470 - val_loss: 0.4353 - val_accuracy: 0.8010\n",
      "Epoch 2/80\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3576 - accuracy: 0.8488 - val_loss: 0.4371 - val_accuracy: 0.8014\n",
      "Epoch 3/80\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3567 - accuracy: 0.8493 - val_loss: 0.4383 - val_accuracy: 0.8010\n",
      "Epoch 4/80\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3554 - accuracy: 0.8498 - val_loss: 0.4498 - val_accuracy: 0.7939\n",
      "Epoch 5/80\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3543 - accuracy: 0.8508 - val_loss: 0.4468 - val_accuracy: 0.7948\n",
      "Epoch 6/80\n",
      "777/782 [============================>.] - ETA: 0s - loss: 0.3531 - accuracy: 0.8518Restoring model weights from the end of the best epoch: 1.\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3532 - accuracy: 0.8517 - val_loss: 0.4508 - val_accuracy: 0.7927\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/80\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.5467 - accuracy: 0.7280 - val_loss: 0.5345 - val_accuracy: 0.7335\n",
      "Epoch 2/80\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.5460 - accuracy: 0.7284 - val_loss: 0.5367 - val_accuracy: 0.7352\n",
      "Epoch 3/80\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.5467 - accuracy: 0.7316 - val_loss: 0.5359 - val_accuracy: 0.7314\n",
      "Epoch 4/80\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.5452 - accuracy: 0.7305 - val_loss: 0.5353 - val_accuracy: 0.7310\n",
      "Epoch 5/80\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.5462 - accuracy: 0.7298 - val_loss: 0.5355 - val_accuracy: 0.7324\n",
      "Epoch 6/80\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5479 - accuracy: 0.7290Restoring model weights from the end of the best epoch: 1.\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.5478 - accuracy: 0.7290 - val_loss: 0.5363 - val_accuracy: 0.7298\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/80\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4032 - accuracy: 0.8156 - val_loss: 0.4186 - val_accuracy: 0.8070\n",
      "Epoch 2/80\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4025 - accuracy: 0.8160 - val_loss: 0.4189 - val_accuracy: 0.8058\n",
      "Epoch 3/80\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4054 - accuracy: 0.8144 - val_loss: 0.4179 - val_accuracy: 0.8067\n",
      "Epoch 4/80\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4033 - accuracy: 0.8154 - val_loss: 0.4177 - val_accuracy: 0.8080\n",
      "Epoch 5/80\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4023 - accuracy: 0.8179 - val_loss: 0.4178 - val_accuracy: 0.8060\n",
      "Epoch 6/80\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4063 - accuracy: 0.8140 - val_loss: 0.4177 - val_accuracy: 0.8084\n",
      "Epoch 7/80\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4032 - accuracy: 0.8172 - val_loss: 0.4178 - val_accuracy: 0.8087\n",
      "Epoch 8/80\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4028 - accuracy: 0.8154 - val_loss: 0.4180 - val_accuracy: 0.8068\n",
      "Epoch 9/80\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3999 - accuracy: 0.8193 - val_loss: 0.4173 - val_accuracy: 0.8073\n",
      "Epoch 10/80\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4017 - accuracy: 0.8182 - val_loss: 0.4180 - val_accuracy: 0.8072\n",
      "Epoch 11/80\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4002 - accuracy: 0.8159 - val_loss: 0.4191 - val_accuracy: 0.8084\n",
      "Epoch 12/80\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3989 - accuracy: 0.8186 - val_loss: 0.4169 - val_accuracy: 0.8095\n",
      "Epoch 13/80\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4003 - accuracy: 0.8160 - val_loss: 0.4179 - val_accuracy: 0.8084\n",
      "Epoch 14/80\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4026 - accuracy: 0.8174 - val_loss: 0.4187 - val_accuracy: 0.8085\n",
      "Epoch 15/80\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4006 - accuracy: 0.8166 - val_loss: 0.4185 - val_accuracy: 0.8092\n",
      "Epoch 16/80\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4023 - accuracy: 0.8170 - val_loss: 0.4180 - val_accuracy: 0.8081\n",
      "Epoch 17/80\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3980 - accuracy: 0.8183 - val_loss: 0.4168 - val_accuracy: 0.8084\n",
      "Epoch 18/80\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4002 - accuracy: 0.8162 - val_loss: 0.4175 - val_accuracy: 0.8094\n",
      "Epoch 19/80\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3989 - accuracy: 0.8202 - val_loss: 0.4175 - val_accuracy: 0.8082\n",
      "Epoch 20/80\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3996 - accuracy: 0.8162 - val_loss: 0.4176 - val_accuracy: 0.8076\n",
      "Epoch 21/80\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3991 - accuracy: 0.8166 - val_loss: 0.4178 - val_accuracy: 0.8084\n",
      "Epoch 22/80\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3967 - accuracy: 0.8185Restoring model weights from the end of the best epoch: 17.\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3969 - accuracy: 0.8184 - val_loss: 0.4189 - val_accuracy: 0.8069\n",
      "Epoch 22: early stopping\n",
      "Epoch 1/80\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3854 - accuracy: 0.8376 - val_loss: 0.5111 - val_accuracy: 0.7647\n",
      "Epoch 2/80\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3772 - accuracy: 0.8397 - val_loss: 0.5118 - val_accuracy: 0.7664\n",
      "Epoch 3/80\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3699 - accuracy: 0.8436 - val_loss: 0.5175 - val_accuracy: 0.7663\n",
      "Epoch 4/80\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3618 - accuracy: 0.8494 - val_loss: 0.5191 - val_accuracy: 0.7622\n",
      "Epoch 5/80\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3513 - accuracy: 0.8555 - val_loss: 0.5308 - val_accuracy: 0.7654\n",
      "Epoch 6/80\n",
      "924/938 [============================>.] - ETA: 0s - loss: 0.3430 - accuracy: 0.8579Restoring model weights from the end of the best epoch: 1.\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3435 - accuracy: 0.8576 - val_loss: 0.5364 - val_accuracy: 0.7647\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/80\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.5332 - accuracy: 0.7450 - val_loss: 0.5528 - val_accuracy: 0.7402\n",
      "Epoch 2/80\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.5336 - accuracy: 0.7437 - val_loss: 0.5458 - val_accuracy: 0.7373\n",
      "Epoch 3/80\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.5339 - accuracy: 0.7446 - val_loss: 0.5492 - val_accuracy: 0.7402\n",
      "Epoch 4/80\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.5324 - accuracy: 0.7462 - val_loss: 0.5451 - val_accuracy: 0.7383\n",
      "Epoch 5/80\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.5330 - accuracy: 0.7407 - val_loss: 0.5520 - val_accuracy: 0.7441\n",
      "Epoch 6/80\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.5340 - accuracy: 0.7435 - val_loss: 0.5531 - val_accuracy: 0.7352\n",
      "Epoch 7/80\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.5327 - accuracy: 0.7439 - val_loss: 0.5494 - val_accuracy: 0.7377\n",
      "Epoch 8/80\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.5305 - accuracy: 0.7461 - val_loss: 0.5423 - val_accuracy: 0.7440\n",
      "Epoch 9/80\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.5306 - accuracy: 0.7462 - val_loss: 0.5458 - val_accuracy: 0.7430\n",
      "Epoch 10/80\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.5310 - accuracy: 0.7460 - val_loss: 0.5468 - val_accuracy: 0.7330\n",
      "Epoch 11/80\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.5308 - accuracy: 0.7427 - val_loss: 0.5463 - val_accuracy: 0.7420\n",
      "Epoch 12/80\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.5325 - accuracy: 0.7427 - val_loss: 0.5701 - val_accuracy: 0.7271\n",
      "Epoch 13/80\n",
      "938/938 [==============================] - ETA: 0s - loss: 0.5320 - accuracy: 0.7428Restoring model weights from the end of the best epoch: 8.\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.5320 - accuracy: 0.7428 - val_loss: 0.5444 - val_accuracy: 0.7340\n",
      "Epoch 13: early stopping\n",
      "Epoch 1/80\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.3661 - accuracy: 0.8439 - val_loss: 0.4344 - val_accuracy: 0.7997\n",
      "Epoch 2/80\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.3665 - accuracy: 0.8434 - val_loss: 0.4353 - val_accuracy: 0.8038\n",
      "Epoch 3/80\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.3637 - accuracy: 0.8448 - val_loss: 0.4344 - val_accuracy: 0.8021\n",
      "Epoch 4/80\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.3615 - accuracy: 0.8462 - val_loss: 0.4379 - val_accuracy: 0.8028\n",
      "Epoch 5/80\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.3633 - accuracy: 0.8456 - val_loss: 0.4420 - val_accuracy: 0.7979\n",
      "Epoch 6/80\n",
      "930/938 [============================>.] - ETA: 0s - loss: 0.3610 - accuracy: 0.8455Restoring model weights from the end of the best epoch: 1.\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.3615 - accuracy: 0.8452 - val_loss: 0.4346 - val_accuracy: 0.8015\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/80\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.5486 - accuracy: 0.7302 - val_loss: 0.5351 - val_accuracy: 0.7319\n",
      "Epoch 2/80\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.5494 - accuracy: 0.7247 - val_loss: 0.5357 - val_accuracy: 0.7348\n",
      "Epoch 3/80\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.5487 - accuracy: 0.7267 - val_loss: 0.5381 - val_accuracy: 0.7378\n",
      "Epoch 4/80\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.5481 - accuracy: 0.7294 - val_loss: 0.5369 - val_accuracy: 0.7290\n",
      "Epoch 5/80\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.5484 - accuracy: 0.7268 - val_loss: 0.5343 - val_accuracy: 0.7306\n",
      "Epoch 6/80\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.5472 - accuracy: 0.7286 - val_loss: 0.5340 - val_accuracy: 0.7329\n",
      "Epoch 7/80\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.5485 - accuracy: 0.7276 - val_loss: 0.5353 - val_accuracy: 0.7345\n",
      "Epoch 8/80\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.5485 - accuracy: 0.7266 - val_loss: 0.5338 - val_accuracy: 0.7347\n",
      "Epoch 9/80\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.5482 - accuracy: 0.7253 - val_loss: 0.5355 - val_accuracy: 0.7340\n",
      "Epoch 10/80\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.5449 - accuracy: 0.7311 - val_loss: 0.5343 - val_accuracy: 0.7306\n",
      "Epoch 11/80\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.5491 - accuracy: 0.7231 - val_loss: 0.5366 - val_accuracy: 0.7335\n",
      "Epoch 12/80\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.5486 - accuracy: 0.7274 - val_loss: 0.5369 - val_accuracy: 0.7282\n",
      "Epoch 13/80\n",
      "937/938 [============================>.] - ETA: 0s - loss: 0.5479 - accuracy: 0.7276Restoring model weights from the end of the best epoch: 8.\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.5479 - accuracy: 0.7276 - val_loss: 0.5346 - val_accuracy: 0.7302\n",
      "Epoch 13: early stopping\n",
      "Epoch 1/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.4038 - accuracy: 0.8147 - val_loss: 0.4176 - val_accuracy: 0.8095\n",
      "Epoch 2/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.4050 - accuracy: 0.8133 - val_loss: 0.4182 - val_accuracy: 0.8082\n",
      "Epoch 3/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.4060 - accuracy: 0.8118 - val_loss: 0.4184 - val_accuracy: 0.8082\n",
      "Epoch 4/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.4065 - accuracy: 0.8126 - val_loss: 0.4172 - val_accuracy: 0.8085\n",
      "Epoch 5/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.4068 - accuracy: 0.8122 - val_loss: 0.4169 - val_accuracy: 0.8095\n",
      "Epoch 6/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.4044 - accuracy: 0.8140 - val_loss: 0.4174 - val_accuracy: 0.8084\n",
      "Epoch 7/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.4050 - accuracy: 0.8132 - val_loss: 0.4204 - val_accuracy: 0.8085\n",
      "Epoch 8/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.4047 - accuracy: 0.8148 - val_loss: 0.4168 - val_accuracy: 0.8084\n",
      "Epoch 9/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.4023 - accuracy: 0.8160 - val_loss: 0.4166 - val_accuracy: 0.8094\n",
      "Epoch 10/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.4027 - accuracy: 0.8156 - val_loss: 0.4177 - val_accuracy: 0.8088\n",
      "Epoch 11/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.4035 - accuracy: 0.8154 - val_loss: 0.4158 - val_accuracy: 0.8102\n",
      "Epoch 12/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.4015 - accuracy: 0.8169 - val_loss: 0.4160 - val_accuracy: 0.8099\n",
      "Epoch 13/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.4020 - accuracy: 0.8150 - val_loss: 0.4164 - val_accuracy: 0.8093\n",
      "Epoch 14/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.4013 - accuracy: 0.8149 - val_loss: 0.4166 - val_accuracy: 0.8093\n",
      "Epoch 15/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.4039 - accuracy: 0.8169 - val_loss: 0.4156 - val_accuracy: 0.8090\n",
      "Epoch 16/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.4010 - accuracy: 0.8177 - val_loss: 0.4163 - val_accuracy: 0.8093\n",
      "Epoch 17/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.4014 - accuracy: 0.8188 - val_loss: 0.4162 - val_accuracy: 0.8102\n",
      "Epoch 18/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.4012 - accuracy: 0.8162 - val_loss: 0.4155 - val_accuracy: 0.8099\n",
      "Epoch 19/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.3997 - accuracy: 0.8180 - val_loss: 0.4179 - val_accuracy: 0.8075\n",
      "Epoch 20/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.4018 - accuracy: 0.8151 - val_loss: 0.4168 - val_accuracy: 0.8092\n",
      "Epoch 21/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.3999 - accuracy: 0.8183 - val_loss: 0.4150 - val_accuracy: 0.8101\n",
      "Epoch 22/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.4002 - accuracy: 0.8176 - val_loss: 0.4148 - val_accuracy: 0.8113\n",
      "Epoch 23/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.3998 - accuracy: 0.8173 - val_loss: 0.4159 - val_accuracy: 0.8090\n",
      "Epoch 24/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.3999 - accuracy: 0.8171 - val_loss: 0.4146 - val_accuracy: 0.8104\n",
      "Epoch 25/80\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.3978 - accuracy: 0.8180 - val_loss: 0.4151 - val_accuracy: 0.8108\n",
      "Epoch 26/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.3986 - accuracy: 0.8178 - val_loss: 0.4147 - val_accuracy: 0.8109\n",
      "Epoch 27/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.3993 - accuracy: 0.8168 - val_loss: 0.4146 - val_accuracy: 0.8110\n",
      "Epoch 28/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.4008 - accuracy: 0.8182 - val_loss: 0.4151 - val_accuracy: 0.8095\n",
      "Epoch 29/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.3970 - accuracy: 0.8177 - val_loss: 0.4155 - val_accuracy: 0.8111\n",
      "Epoch 30/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.3984 - accuracy: 0.8172 - val_loss: 0.4151 - val_accuracy: 0.8099\n",
      "Epoch 31/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.3983 - accuracy: 0.8188 - val_loss: 0.4138 - val_accuracy: 0.8113\n",
      "Epoch 32/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.3983 - accuracy: 0.8184 - val_loss: 0.4142 - val_accuracy: 0.8115\n",
      "Epoch 33/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.3976 - accuracy: 0.8200 - val_loss: 0.4142 - val_accuracy: 0.8111\n",
      "Epoch 34/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.3965 - accuracy: 0.8190 - val_loss: 0.4150 - val_accuracy: 0.8101\n",
      "Epoch 35/80\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.3996 - accuracy: 0.8179 - val_loss: 0.4142 - val_accuracy: 0.8097\n",
      "Epoch 36/80\n",
      "936/938 [============================>.] - ETA: 0s - loss: 0.3974 - accuracy: 0.8178Restoring model weights from the end of the best epoch: 31.\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.3975 - accuracy: 0.8178 - val_loss: 0.4139 - val_accuracy: 0.8125\n",
      "Epoch 36: early stopping\n",
      "Epoch 1/80\n",
      "1164/1164 [==============================] - 3s 2ms/step - loss: 0.4004 - accuracy: 0.8279 - val_loss: 0.5030 - val_accuracy: 0.7660\n",
      "Epoch 2/80\n",
      "1164/1164 [==============================] - 3s 2ms/step - loss: 0.3917 - accuracy: 0.8316 - val_loss: 0.5010 - val_accuracy: 0.7672\n",
      "Epoch 3/80\n",
      "1164/1164 [==============================] - 3s 2ms/step - loss: 0.3824 - accuracy: 0.8369 - val_loss: 0.5058 - val_accuracy: 0.7693\n",
      "Epoch 4/80\n",
      "1164/1164 [==============================] - 3s 2ms/step - loss: 0.3750 - accuracy: 0.8410 - val_loss: 0.5070 - val_accuracy: 0.7678\n",
      "Epoch 5/80\n",
      "1164/1164 [==============================] - 3s 2ms/step - loss: 0.3672 - accuracy: 0.8448 - val_loss: 0.5104 - val_accuracy: 0.7673\n",
      "Epoch 6/80\n",
      "1164/1164 [==============================] - 3s 2ms/step - loss: 0.3588 - accuracy: 0.8486 - val_loss: 0.5186 - val_accuracy: 0.7684\n",
      "Epoch 7/80\n",
      "1160/1164 [============================>.] - ETA: 0s - loss: 0.3509 - accuracy: 0.8546Restoring model weights from the end of the best epoch: 2.\n",
      "1164/1164 [==============================] - 3s 2ms/step - loss: 0.3509 - accuracy: 0.8546 - val_loss: 0.5212 - val_accuracy: 0.7659\n",
      "Epoch 7: early stopping\n",
      "Epoch 1/80\n",
      "1164/1164 [==============================] - 4s 3ms/step - loss: 0.5397 - accuracy: 0.7397 - val_loss: 0.5460 - val_accuracy: 0.7401\n",
      "Epoch 2/80\n",
      "1164/1164 [==============================] - 4s 3ms/step - loss: 0.5366 - accuracy: 0.7414 - val_loss: 0.5484 - val_accuracy: 0.7397\n",
      "Epoch 3/80\n",
      "1164/1164 [==============================] - 4s 3ms/step - loss: 0.5371 - accuracy: 0.7411 - val_loss: 0.5527 - val_accuracy: 0.7358\n",
      "Epoch 4/80\n",
      "1164/1164 [==============================] - 4s 3ms/step - loss: 0.5341 - accuracy: 0.7421 - val_loss: 0.5475 - val_accuracy: 0.7416\n",
      "Epoch 5/80\n",
      "1164/1164 [==============================] - 4s 3ms/step - loss: 0.5356 - accuracy: 0.7413 - val_loss: 0.5463 - val_accuracy: 0.7362\n",
      "Epoch 6/80\n",
      "1164/1164 [==============================] - ETA: 0s - loss: 0.5358 - accuracy: 0.7429Restoring model weights from the end of the best epoch: 1.\n",
      "1164/1164 [==============================] - 4s 3ms/step - loss: 0.5358 - accuracy: 0.7429 - val_loss: 0.5515 - val_accuracy: 0.7404\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/80\n",
      "1164/1164 [==============================] - 6s 5ms/step - loss: 0.3780 - accuracy: 0.8372 - val_loss: 0.4351 - val_accuracy: 0.7996\n",
      "Epoch 2/80\n",
      "1164/1164 [==============================] - 6s 5ms/step - loss: 0.3753 - accuracy: 0.8385 - val_loss: 0.4409 - val_accuracy: 0.7965\n",
      "Epoch 3/80\n",
      "1164/1164 [==============================] - 6s 5ms/step - loss: 0.3736 - accuracy: 0.8382 - val_loss: 0.4344 - val_accuracy: 0.8024\n",
      "Epoch 4/80\n",
      "1164/1164 [==============================] - 6s 5ms/step - loss: 0.3741 - accuracy: 0.8383 - val_loss: 0.4415 - val_accuracy: 0.7992\n",
      "Epoch 5/80\n",
      "1164/1164 [==============================] - 6s 5ms/step - loss: 0.3731 - accuracy: 0.8390 - val_loss: 0.4363 - val_accuracy: 0.7971\n",
      "Epoch 6/80\n",
      "1164/1164 [==============================] - 6s 5ms/step - loss: 0.3724 - accuracy: 0.8385 - val_loss: 0.4310 - val_accuracy: 0.8028\n",
      "Epoch 7/80\n",
      "1164/1164 [==============================] - 6s 5ms/step - loss: 0.3725 - accuracy: 0.8407 - val_loss: 0.4363 - val_accuracy: 0.7995\n",
      "Epoch 8/80\n",
      "1164/1164 [==============================] - 6s 5ms/step - loss: 0.3726 - accuracy: 0.8396 - val_loss: 0.4484 - val_accuracy: 0.7905\n",
      "Epoch 9/80\n",
      "1164/1164 [==============================] - 6s 5ms/step - loss: 0.3713 - accuracy: 0.8404 - val_loss: 0.4326 - val_accuracy: 0.7986\n",
      "Epoch 10/80\n",
      "1164/1164 [==============================] - 6s 5ms/step - loss: 0.3696 - accuracy: 0.8425 - val_loss: 0.4348 - val_accuracy: 0.7992\n",
      "Epoch 11/80\n",
      "1164/1164 [==============================] - 5s 5ms/step - loss: 0.3694 - accuracy: 0.8415 - val_loss: 0.4302 - val_accuracy: 0.8037\n",
      "Epoch 12/80\n",
      "1164/1164 [==============================] - 6s 5ms/step - loss: 0.3684 - accuracy: 0.8420 - val_loss: 0.4440 - val_accuracy: 0.7933\n",
      "Epoch 13/80\n",
      "1164/1164 [==============================] - 6s 5ms/step - loss: 0.3674 - accuracy: 0.8421 - val_loss: 0.4334 - val_accuracy: 0.7995\n",
      "Epoch 14/80\n",
      "1164/1164 [==============================] - 6s 5ms/step - loss: 0.3661 - accuracy: 0.8443 - val_loss: 0.4349 - val_accuracy: 0.8047\n",
      "Epoch 15/80\n",
      "1164/1164 [==============================] - 6s 5ms/step - loss: 0.3653 - accuracy: 0.8455 - val_loss: 0.4311 - val_accuracy: 0.8036\n",
      "Epoch 16/80\n",
      "1164/1164 [==============================] - 6s 5ms/step - loss: 0.3653 - accuracy: 0.8450 - val_loss: 0.4289 - val_accuracy: 0.8039\n",
      "Epoch 17/80\n",
      "1164/1164 [==============================] - 6s 5ms/step - loss: 0.3654 - accuracy: 0.8456 - val_loss: 0.4324 - val_accuracy: 0.8036\n",
      "Epoch 18/80\n",
      "1164/1164 [==============================] - 6s 5ms/step - loss: 0.3644 - accuracy: 0.8450 - val_loss: 0.4302 - val_accuracy: 0.8038\n",
      "Epoch 19/80\n",
      "1164/1164 [==============================] - 6s 5ms/step - loss: 0.3625 - accuracy: 0.8469 - val_loss: 0.4296 - val_accuracy: 0.8037\n",
      "Epoch 20/80\n",
      "1164/1164 [==============================] - 6s 5ms/step - loss: 0.3629 - accuracy: 0.8467 - val_loss: 0.4320 - val_accuracy: 0.8025\n",
      "Epoch 21/80\n",
      "1158/1164 [============================>.] - ETA: 0s - loss: 0.3618 - accuracy: 0.8467Restoring model weights from the end of the best epoch: 16.\n",
      "1164/1164 [==============================] - 6s 5ms/step - loss: 0.3619 - accuracy: 0.8468 - val_loss: 0.4366 - val_accuracy: 0.8020\n",
      "Epoch 21: early stopping\n",
      "Epoch 1/80\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 0.5504 - accuracy: 0.7236 - val_loss: 0.5355 - val_accuracy: 0.7344\n",
      "Epoch 2/80\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 0.5479 - accuracy: 0.7264 - val_loss: 0.5356 - val_accuracy: 0.7343\n",
      "Epoch 3/80\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 0.5495 - accuracy: 0.7245 - val_loss: 0.5359 - val_accuracy: 0.7307\n",
      "Epoch 4/80\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 0.5474 - accuracy: 0.7269 - val_loss: 0.5340 - val_accuracy: 0.7333\n",
      "Epoch 5/80\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 0.5475 - accuracy: 0.7292 - val_loss: 0.5354 - val_accuracy: 0.7325\n",
      "Epoch 6/80\n",
      "1164/1164 [==============================] - 13s 12ms/step - loss: 0.5490 - accuracy: 0.7269 - val_loss: 0.5335 - val_accuracy: 0.7318\n",
      "Epoch 7/80\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 0.5503 - accuracy: 0.7258 - val_loss: 0.5398 - val_accuracy: 0.7272\n",
      "Epoch 8/80\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 0.5492 - accuracy: 0.7262 - val_loss: 0.5338 - val_accuracy: 0.7375\n",
      "Epoch 9/80\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 0.5485 - accuracy: 0.7280 - val_loss: 0.5339 - val_accuracy: 0.7312\n",
      "Epoch 10/80\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 0.5483 - accuracy: 0.7264 - val_loss: 0.5332 - val_accuracy: 0.7303\n",
      "Epoch 11/80\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 0.5491 - accuracy: 0.7262 - val_loss: 0.5343 - val_accuracy: 0.7310\n",
      "Epoch 12/80\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 0.5497 - accuracy: 0.7253 - val_loss: 0.5330 - val_accuracy: 0.7341\n",
      "Epoch 13/80\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 0.5478 - accuracy: 0.7272 - val_loss: 0.5326 - val_accuracy: 0.7330\n",
      "Epoch 14/80\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 0.5479 - accuracy: 0.7268 - val_loss: 0.5369 - val_accuracy: 0.7362\n",
      "Epoch 15/80\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 0.5469 - accuracy: 0.7272 - val_loss: 0.5330 - val_accuracy: 0.7314\n",
      "Epoch 16/80\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 0.5483 - accuracy: 0.7281 - val_loss: 0.5357 - val_accuracy: 0.7329\n",
      "Epoch 17/80\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 0.5483 - accuracy: 0.7271 - val_loss: 0.5329 - val_accuracy: 0.7355\n",
      "Epoch 18/80\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 0.5482 - accuracy: 0.7276 - val_loss: 0.5322 - val_accuracy: 0.7362\n",
      "Epoch 19/80\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 0.5480 - accuracy: 0.7264 - val_loss: 0.5353 - val_accuracy: 0.7377\n",
      "Epoch 20/80\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 0.5478 - accuracy: 0.7261 - val_loss: 0.5332 - val_accuracy: 0.7362\n",
      "Epoch 21/80\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 0.5478 - accuracy: 0.7247 - val_loss: 0.5332 - val_accuracy: 0.7331\n",
      "Epoch 22/80\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 0.5483 - accuracy: 0.7258 - val_loss: 0.5389 - val_accuracy: 0.7359\n",
      "Epoch 23/80\n",
      "1161/1164 [============================>.] - ETA: 0s - loss: 0.5475 - accuracy: 0.7268Restoring model weights from the end of the best epoch: 18.\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 0.5476 - accuracy: 0.7267 - val_loss: 0.5325 - val_accuracy: 0.7375\n",
      "Epoch 23: early stopping\n",
      "Epoch 1/80\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.4080 - accuracy: 0.8127 - val_loss: 0.4133 - val_accuracy: 0.8105\n",
      "Epoch 2/80\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.4042 - accuracy: 0.8160 - val_loss: 0.4125 - val_accuracy: 0.8117\n",
      "Epoch 3/80\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.4044 - accuracy: 0.8150 - val_loss: 0.4127 - val_accuracy: 0.8103\n",
      "Epoch 4/80\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.4051 - accuracy: 0.8140 - val_loss: 0.4126 - val_accuracy: 0.8102\n",
      "Epoch 5/80\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.4033 - accuracy: 0.8164 - val_loss: 0.4132 - val_accuracy: 0.8076\n",
      "Epoch 6/80\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.4041 - accuracy: 0.8148 - val_loss: 0.4118 - val_accuracy: 0.8115\n",
      "Epoch 7/80\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.4032 - accuracy: 0.8162 - val_loss: 0.4129 - val_accuracy: 0.8093\n",
      "Epoch 8/80\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.4036 - accuracy: 0.8153 - val_loss: 0.4124 - val_accuracy: 0.8093\n",
      "Epoch 9/80\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.4037 - accuracy: 0.8155 - val_loss: 0.4122 - val_accuracy: 0.8108\n",
      "Epoch 10/80\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.4028 - accuracy: 0.8154 - val_loss: 0.4114 - val_accuracy: 0.8102\n",
      "Epoch 11/80\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.4041 - accuracy: 0.8148 - val_loss: 0.4113 - val_accuracy: 0.8123\n",
      "Epoch 12/80\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.4037 - accuracy: 0.8168 - val_loss: 0.4106 - val_accuracy: 0.8111\n",
      "Epoch 13/80\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.4025 - accuracy: 0.8148 - val_loss: 0.4113 - val_accuracy: 0.8121\n",
      "Epoch 14/80\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.4024 - accuracy: 0.8161 - val_loss: 0.4118 - val_accuracy: 0.8119\n",
      "Epoch 15/80\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.4017 - accuracy: 0.8152 - val_loss: 0.4108 - val_accuracy: 0.8133\n",
      "Epoch 16/80\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.4012 - accuracy: 0.8189 - val_loss: 0.4104 - val_accuracy: 0.8123\n",
      "Epoch 17/80\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.4004 - accuracy: 0.8173 - val_loss: 0.4115 - val_accuracy: 0.8116\n",
      "Epoch 18/80\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.4004 - accuracy: 0.8184 - val_loss: 0.4097 - val_accuracy: 0.8110\n",
      "Epoch 19/80\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.4013 - accuracy: 0.8157 - val_loss: 0.4100 - val_accuracy: 0.8110\n",
      "Epoch 20/80\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.4017 - accuracy: 0.8172 - val_loss: 0.4102 - val_accuracy: 0.8115\n",
      "Epoch 21/80\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.4015 - accuracy: 0.8170 - val_loss: 0.4102 - val_accuracy: 0.8133\n",
      "Epoch 22/80\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3997 - accuracy: 0.8201 - val_loss: 0.4102 - val_accuracy: 0.8118\n",
      "Epoch 23/80\n",
      "1164/1164 [==============================] - ETA: 0s - loss: 0.3998 - accuracy: 0.8172Restoring model weights from the end of the best epoch: 18.\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3998 - accuracy: 0.8172 - val_loss: 0.4101 - val_accuracy: 0.8128\n",
      "Epoch 23: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train each model with varying amounts of data\n",
    "train_sizes = [5000, 10000, 15000, 20000, 25000, 30000, 38000]\n",
    "histories = {m['name']: [] for m in models}\n",
    "for size in train_sizes:\n",
    "    for m in models:\n",
    "        history = m['model'].fit(X_train[:size], y_train[:size], epochs=80, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "        histories[m['name']].append(history)\n",
    "\n",
    "# Plot the accuracy as a function of training data size for each model\n",
    "fig, ax = plt.subplots()\n",
    "for m in models:\n",
    "    accuracies = []\n",
    "    for i in range(len(train_sizes)):\n",
    "        accuracy = histories[m['name']][i].history['val_accuracy'][-1]\n",
    "        accuracies.append(accuracy)\n",
    "    ax.plot(train_sizes, accuracies, label=m['name'])\n",
    "ax.set_xlabel('Data Size')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy as a function of training data size for different deep learning models')\n",
    "ax.legend()\n",
    "plt.savefig(\"../fig/unified_accuracy_2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
